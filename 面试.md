# 【并发】

## Thread和Runnable关系

- Thread是实现了Runnable接口的类，使得Runnable的run方法可以多线程执行
- 因为类的单一继承原则，所以推荐多使用Runnabe接口，将业务逻辑封装在Runnable接口里

## 处理线程返回值

- 主线程等待法

  ![image-20230419101702866](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230419101702866.png)

- Thread类的join()方法阻塞当前线程以等待子线程处理

  `join`合并线程，待此线程执行完成后，再执行其他线程，其他线程阻塞，就像插队一样

  ![image-20230419101752379](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230419101752379.png)

- 通过Callable接口实现：FutrueTask Or 线程池获取

  - FutureTask实现RunnableFuture接口，RunnableFuture继承Runnable；

    所以可以通过Thread启动线程执行FutureTask

    ![image-20230419102307733](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230419102307733.png)

  - 线程池：

    ![image-20230419102603366](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230419102603366.png)





## 线程状态

### 操作系统

### Java线程状态

1. **初始(NEW)：**

   新创建了一个线程对象，但还没有调用start()方法。

2. **运行(RUNNABLE)：**

  就绪（READY）：准备好资源， 等待调度

  运行中（RUNNING）：被CPU调度，运行中

3. **阻塞(BLOCKED)：**表示线程阻塞于锁。

4. **等待(WAITING)：**进入该状态的线程需要等待其他线程做出一些特定动作唤醒（通知或中断）。

5. **超时等待(TIMED_WAITING)：**该状态不同于WAITING，它可以在指定的时间后自行返回。

6. **终止(TERMINATED)：**表示该线程已经执行完毕。

wait()方法会释放锁，不设置等待时间进入WAITING，设置等待时间进入TIMED_WAITING，唤醒后进入BLOCKED（需要重新竞争锁）

sleep(timeout)方法不会释放锁，进入TIMED_WAITING，唤醒后进入RUNNABLE(READY)

![image-20230419110408995](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230419110408995.png)

## sleep和wait区别

- **sleep是Thread类的方法，wait是Object类中定义的方法**

  因为sleep不释放锁，是线程的操作，wait释放锁，要对资源操作

- **sleep方法可以在任何地方使用，wait方法只能在synchronized方法/代码块上使用**

- sleep后唤醒的线程进入就绪态，wait后唤醒的线程进入阻塞态（竞争锁）

- **本质区别：**

  - Thread.sleep只会让出CPU，不会导致锁行为的改变
  - Object.wait不仅让出CPU，还会释放自己的锁

## notify和notifyAll区别

- **notifyAll**唤醒所有线程，让所有线程都加入锁池参与竞争；

- **notify**会随机唤醒一个线程进入锁池；

  随机算法基于一个线程调度器（先进先出、最短耗时任务优先、时间片轮转、最大最小公平算法）

  

- **锁池:**竞争锁失败的对象进入锁池，等待锁释放后竞争锁

- **等待池:**假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁后，进入到了该对象的等待池中

  

如果线程调用了对象的 wait()方法，那么线程便会处于该对象的**等待池**中，等待池中的线程**不会去竞争该对象的锁**。

当有线程调用了对象的 **notifyAll**()方法（唤醒所有 wait 线程）或 **notify**()方法（只随机唤醒一个 wait 线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。

除非再次调用wait方法，否则锁池中竞争失败的线程还会留在锁池里竞争锁；而拿到锁的对象会在执行完同步代码块后释放锁，进入等待池

**这里就有一个问题：notify只唤醒一个线程去竞争锁，如果这个线程执行完后释放锁，但没有再次执行notify唤醒其他在等待池中的线程，那么此时哪怕有锁，但锁池是空的，等待的线程将一直处于等待状态**

**生产者消费者模型中，需要用while语句判断是否需要等待，因为如果是if语句，判断之后来不及执行后面的代码就发生线程切换，下次唤醒时可能还不满足要求还需要等待，如果是if语句那就不会再被wait了，所以要用while循环判断是否等待**

## wait和notify为什么要在同步块中

假设一个生产者/消费者模型：

1. 一个消费者take资源，发现为空
2. 在消费者wait之前，当前线程被挂起
3. 生产者add资源，notify
4. 消费者线程被唤醒，然后自己又调用了wait
5. 若此时生产者不再生产，那么消费者会一直被挂起，就有一份资源一直无法被消费；

**竞态条件**（race condition）：两个或者以上进程或者线程并发执行时，其最终的结果依赖于进程或者线程执行的精确时序。

也就是说，wait和notify方法存在竞态条件，如果不能按照顺序执行，会出现Lost wake-up problem；所以需要放在同步块中保证执行顺序

## yield

**Thread.yield()方法作用是：暂停当前正在执行的线程对象，并执行其他线程。**

yield()方法使得当前线程回到RUNNABLE的READY状态，并且和其他线程一起等待CPU的调度；因此它不能做到让步目的（因为可能自己也会再次被调度）

## 各种锁

- **重量级锁：** 获取锁失败立刻进入阻塞状态

- **轻量级锁：** 在进入方法时，采用**CAS**机制，标记为正在执行；退出方法时，标记为无人执行

  轻量级锁适合很少出现多个线程竞争一个锁的情况

  - **自旋锁：** 获取锁失败会持续尝试获取锁一段时间再阻塞

  - **自适应自旋锁：** 会根据线程最近获得锁的状态来调整循环次数的自旋锁

- **偏向锁：** 在运行过程中，对象的锁偏向某个线程，即某个线程获得锁且当他下次再想获得锁时，不需要再加锁

  偏向锁加锁过程类似于轻量级锁，采用CAS机制标记该方法正在执行；但只有遇到其他线程尝试竞争偏向锁时，持有偏向锁状态的线程才会释放锁，线程不会主动去释放偏向锁

- **悲观锁、乐观锁：**

  - **悲观锁：**悲观地认为每次操作都会冲突，所以要加锁
  - **乐观锁：**乐观地认为每次操作都不会冲突，只在发生冲突的时候尝试解决

## volatile关键字

**volatile保证变量的可见性：**

当一个变量被声明为volatile时，在编译成汇编指令时，会有一个给**寄存器+0的空操作并上一个lock前缀**

处理器遇到lock指令时，如果数据在内部缓存，处理器会锁定此缓存区域，并在处理完成后把结果刷入主存中，同时利用**缓存一致性协议**，保证其他处理器的缓存数据一致性（处理器会强制让被修改数据在自己缓存中的地址无效，必须去主存取）

****

**volatile保证变量的有序性：**

虚拟机在进行代码编译优化的时候，对于那些改变顺序之后会对最终变量的值不会造成影响的代码，是有可能对他们进行**重排序**的

声明为volatile的变量，会被禁止指令重排

****

**volatile不一定能保证一个变量的线程安全：**

比如Java中的运算并非**原子操作**，多线程对一个变量累加的过程会出现线程不安全导致结果不符合预期

**虽然volatile保证可见性，保证当前读的都是最新值，但是读到值和修改值非原子操作，中间值可能会发生变化，所以无法保证原子性**

## synchronized关键字

synchronized关键字，可以对对象或同步代码块加锁（本质都是对对象加锁），

jdk1.6以前时重量级锁，开销很大，之后进行了优化，加入了锁升级的机制（偏向锁->自旋锁->重量级锁）

对象在内存中的锁相关信息存放在对象头的Markword里

****

**偏向锁：** 创建对象时，对象Markwod拥有偏向锁标志位，默认不生效；当线程执行到临界区时，会利用CAS操作，插入线程id到Markword并修改偏向锁标志位

之后线程执行过程中，只要没有其他线程竞争，该线程不会被同步块进行加锁解锁（通过线程id判断是否是同一个线程）

**锁膨胀：** 出现两个线程竞争锁时，偏向锁失效，此时锁会膨胀，升级为轻量级锁

**锁撤销：** 偏向锁失效会被撤销，步骤如下：

1. 在一个安全点停止拥有锁的线程。
2. 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。
3. 唤醒当前线程，将当前锁升级成轻量级锁。

****

**轻量级锁**

锁升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。下面先简单描述下锁撤销之后，升级为轻量级锁的过程：

1. 线程在自己的栈桢中创建锁记录 LockRecord。
2. 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。
3. 将锁记录中的Owner指针指向锁对象。
4. 将锁对象的对象头的MarkWord替换为指向锁记录的指针。

**轻量级锁的实现是自旋锁和自适应自旋锁（获取锁失败后会自旋一段时间）**

自旋超出一定次数后锁会膨胀为重量级锁

****

**重量级锁**

轻量级锁膨胀之后，就升级为重量级锁了。重量级锁是依赖对象内部的monitor锁来实现的，而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为**互斥锁**。

重量级锁开销很大，因为执行阻塞和唤醒线程时都需要操作系统来帮忙，需要将操作系统**从用户态转换到内核态**，这个过程消耗很多时间

## Lock锁和Sync锁

- **语法层面：**
  - synchronized是关键字，是Java在JVM层面实现的锁
  - Lock是接口，是Java在API层面实现的锁
  - 使用synchronized时，退出同步代码块，锁会自动释放；使用Lock锁时，需要手动释放
- **功能层面：**
  - 二者均属于悲观锁，都具备基本的互斥、同步和锁重入功能
  - Lock锁提供了许多synchronized不具备的功能，如获取等待状态、公平锁、可打断、可超时、多条件变量等功能
  - Lock有适合不同场景的实现，如ReentrantLock、ReentrantReadWriteLock（更适合读多写少场景）
- **性能层面：**
  - 竞争很少时，synchronized利用锁升级机制做了优化
  - 竞争激烈时，Lock实现会提供更好的性能

## CAS

**CAS(V,A,B)**

- V：主存中的共享变量值
- A：工作区中的共享变量副本值，预期值
- B：需要将共享变量更新到的最新值

**核心：**在将B值写入到V之前要比较A值和V值是否相同，如果不相同证明此时V值已经被其他线程改变，重新将V值赋给A，并重新计算得到B，如果相同，则将B值赋给V

****

**Java中CAS原子类**

1. AtomicBoolean
2. AtomicInteger
3. AtomicLong
4. AtomicReference

****

**ABA问题：**如果一个操作实行+1-1操作，最终结果是没有变化的，但实际上当前变量已经被修改过了，CAS却会成功

Java 中提供了 AtomicStampedReference 这个类，可以进行版本控制

****

**Java8对CAS的优化**

线程密集时，很多线程对变量的修改不成功，白白循环浪费资源；

Java8引入cell[]数组，当有较多线程需要修改变量时，会对线程分组，每一组线程对一个cell元素进行CAS操作，再最中汇总（相加）cell的所有元素；

## 死锁

**死锁：**

多个线程互相持有对方需要的资源，并向对方请求自己的资源，形成了永久的僵持状态的循环链条

**产生死锁的必要条件：**

- **互斥条件**

  一个资源每次只能被一个进程使用。

- **请求并保持条件**

  一个进程因请求资源而阻塞时，对已获得的资源保持不放。

- **不剥夺条件**

  进程已获得的资源，在未使用完前，不能强行剥夺

- **循环等待条件**

  若干进程之间形成一种头尾相接的循环等待资源关系

**案例：**

```java
public class DeadLockDemo {  
    private static String A="A";  
    private static String B="B";  
    public static void main(String[] args){  
        new DeadLockDemo().deadLock();  
    }   
    private void deadLock(){  
        Thread threadA=new Thread(new Runnable(){  
            @Override  
            public void run(){  
                synchronized(A){  
                    try {  
                        Thread.currentThread().sleep(2000);
                    } catch (InterruptedException e) {   
                        e.printStackTrace();  
                    }  
                    synchronized(B){  
                        System.out.println("AB");  
                    }  
                }  
            }  
        });  
        Thread threadB=new Thread(new Runnable(){  
            @Override  
            public void run(){  
                synchronized(B){  
                    try {  
                        Thread.currentThread().sleep(2000);  
                    } catch (InterruptedException e) {   
                        e.printStackTrace();  
                    }  
                    synchronized(A){  
                        System.out.println("BA");  
                    }  
                }  
            }  
        });  
        threadA.start();
        Thread.currentThread().sleep(1000);
        threadB.start();  
    }  
} 
```

## 线程池

> 线程池是一种利用池化技术思想来实现的线程管理技术，主要是为了复用线程、便利地管理线程和任务、并将线程的创建和任务的执行解耦开来。
>
> **线程池的优点：**
>
> 1. 降低资源消耗，复用已创建的线程来降低创建和销毁线程的消耗。
> 2. 提高响应速度，任务到达时，可以不需要等待线程的创建立即执行。
> 3. 提高线程的可管理性，使用线程池能够统一的分配、调优和监控。
>
> - 降低资源消耗，复用已创建的线程来降低创建和销毁线程的消耗。
> - **提高响应速度**，任务到达时，可以不需要等待线程的创建立即执行。
> - **提高线程的可管理性**，使用线程池能够统一的分配、调优和监控。
>
> **Java提供的线程池：**通过`Executors`类提供的静态工厂方法创建
>
> - newCachedThreadPool：核心线程数为0，超过60秒空闲自动回收
> - newFixedThreadPool：定长线程池，超出线程会在阻塞队列上等待
> - newScheduledThreadPool：定长线程池，支持定时和周期性任务的执行
> - newSingleThreadExecutor：单线程化的线程池，采用特定算法(FIFO,LIFO,优先级)执行队列中的任务

![图片](https://mmbiz.qpic.cn/mmbiz_gif/GLeh42uInXTjxNaj1t0BwIBXIG4UCkqll1aWANTRNiclV0LVPw8gXRb92d1hL5A9jBEdhLumCsILjbgAJrQpLyQ/640?wx_fmt=gif&wxfrom=5&wx_lazy=1)

- **int corePoolSize**：核心线程数

- **int maximumPoolSize**：最大线程数

- **long keepAliveTime**：非核心线程的空闲时间

- **TimeUnit unit**：空闲时间的单位

- **BlockingQueue<Runnable> workQueue**：任务队列（线程安全的阻塞队列）

- **ThreadFactory threadFactory**：线程工厂

- **RejectedExecutionHandler handler**：拒绝策略

![图片](https://mmbiz.qpic.cn/mmbiz_png/GLeh42uInXTjxNaj1t0BwIBXIG4UCkqlNOR6EbX3EVhyfp7fSy80IweianoAMNR6fHWicCpU9f9iaEickMyDls6BZQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)







# 【MySQL】

## 什么是索引

数据库维护了特定的数据结构，以满足特定的查找算法，从而快速定位数据，这种存储结构就是索引，其设计思想基于空间换时间

## 索引分类

- 数据结构分类：B+树、Hash索引、Full-Text索引
- 物理存储分类：聚簇索引（主键索引）、二级索引（辅助索引）
  - 聚簇索引：索引值和数据存在一块，主键索引即聚簇索引
  - 二级索引：索引值和主键放一起，可能需要回表
- 字段特性分类：主键索引、唯一索引、常规索引、全文索引
- 字段个数分类：单列索引、联合索引

## 索引的优缺点

**优点：**

- 提高数据检索效率，降低数据库IO成本
- 唯一索引保证数据唯一性
- 使用分组、排序子句进行数据检索时，可以显著减少查询中分组和排序的时间
- 加速两个表的连接，一般是在外键上创建索引

**缺点：**

- 占用物理空间，索引越多空间越大
- 创建和维护索引需要耗费时间，会降低表的增删改效率

## 创建索引的方式

- CREATE语句创建表时指明

  ```mysql
  CREATE TABLE user {
  	id INT AUTO_INCREMENT PRIMARY KEY
  };
  
  CREATE TABLE user {
  	id INT,
  	INDEX index_id(id)
  };
  ```

- `ALTER TABLE` 

  ```mysql
  ALTER TABLE user ADD INDEX name_index(name);
  ```

- `CREATE INDEX`

  ```mysql
  CREATE INDEX name_index ON user(name);
  ```

## B+树索引

默认存储引擎 InnoDB 使用b+树索引

- **B+树的磁盘读写次数少，且代价更低：**

  B+树是一棵平衡的多路查找树，其高度较低（相较于二叉查找树），且因为仅在叶子结点存放索引值所以内存占用少（相较于b树），所以一次可以加载更多的节点，磁盘寻址加载次数少

- **B+树范围查找优势：**

  B+树的叶子结点之间是一个有序的双向链表（相较于hash结构），可以很好的支持范围查找、模糊匹配，不需要跨层访问

**相较于其他数据结构：**

- `链表`：B+树维护了树形结构，满足特定查找算法，效率更高
- `hash表`：等值查询方面hash表更有优势，但B+树底层叶子结点构成有序双向循环链表，在范围查询方面效率更高
- `B树`：仅在叶子结点存储索引值和主键（聚簇索引存数据），并将叶子结点串成双向循环链表；磁盘IO代价更小，固定时间复杂度为（logn）且大大增加区间访问性，范围查询效率更快
- `红黑树`：B+树是多路查找树，高度更低，磁盘IO次数更少

**B+树分裂：**

当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针

## 存储引擎比较

InnoDB引擎相比MyISAM引擎：

- 多了行级锁
- 支持事务
- 支持外键

![](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master1fb61b5d074f4312ae90196b97f5b049.png)

## 一条sql执行的很慢的原因

**偶尔很慢：**

- **数据库同步数据到磁盘（刷新脏页）：**

  数据库会在内存中更新数据并写入redolog日志，在空闲时同步到磁盘；如果redolog写满了会暂停其他工作去同步磁盘，可能导致SQL执行慢了

- **拿不到锁：**

  可能当前执行的SQL语句涉及的表被别人加锁了，需要等别人释放锁才能拿到锁

  `show processlist`:显示用户正在运行的线程，可以从command和status字段查看当前线程正处于的状态，判断是否在等待锁

- **SQL写得太烂了：**比如在在循环语句里写sql

**针对一直很慢的情况：**

- **没建立索引或者索引失效，走全表扫描**

  - 不满足最左前缀原则
  - 使用运算或函数

- **有索引，但执行全表扫描**

  系统根据**索引的区分度**（`count(distinct 具体的列) / count(*)`）来判断是否要走索引，区分度越高说明索引上不同的值越多，走索引查询越有优势

  但是系统是通过抽样的方式来预测索引的区分度的，可能会因为统计的失误导致走了全表扫描

  ```mysql
  -- 强制使用索引
  select * from t force index(a) where c < 100 and c < 100000;
  -- 查询基数与实际是否符合
  show index from t;
  -- 重新统计索引基数
  analyze table t;
  ```

## ？慢SQL优化

**1.配置慢查询**

```mysql
SET GLOBAL slow_query_log='ON';
SET GLOBAL long_query_time=2;
```

```properties
long_query_time=2
slow-query-log=On
```

**2.分析慢查询日志，定位执行效率比较低的SQL**

**3.通过explain关键字分析SQL的执行计划**

关注的字段：

- **type：**
  - type=ALL，全表扫描，MySQL遍历全表来找到匹配行
  - type=index，索引全扫描
  - type=range，索引范围扫描
  - type=eq_ref，唯一索引
  - type=NULL，MySQL不用访问表或者索引，直接就能够得到结果（性能最好）
- **possible_keys：** 可能用到的索引
- **key：** 实际用到的索引
- **key_length:** 实际使用的索引字段的长度
- **rows：**扫描的行数
- **extra：**
  - using index：覆盖索引，不回表
  - using where：回表查询
  - using filesort：需要额外的排序，不能通过索引得到排序结果

**4.优化**

- **索引优化：**

  - 尽量覆盖索引，5.6支持索引下推

  - 组合索引符合最左匹配原则，同时要避免索引失效

  - 再写多读少的场景下，可以选择普通索引而不要唯一索引

    因为执行更新语句时，如果数据页没有在内存中，会将更新操作缓存到 change buffer 中，之后再进行 merge,真正进行数据更新，减少磁盘IO，提高性能

    而change buffer主要用于**二级非唯一索引数据**的新增、修改或删除操作，不适用于主键索引、空间索引、全文索引和唯一索引，所以写多读少可以用普通索引

  - 索引建立原则（一般建在where和order by，基数要大，区分度要高，不要过度索引，外键建索引）

- **SQL优化**

  - 分页查询优化：主键自增的表，limit查询可以通过限定主键范围来确定页号
  - insert优化：
    - 多条插入语句写成一条
    - 在事务中插数据
    - 数据有序插入


## 事务/四大特性

**事务：** 事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，即这一组数据库命令要么同时成功，要么同时失败

**四大特性：**

- **A：Atomic 原子性** 事务是不可分割的最小操作单元，要么全部执行，要么全部不执行；
- **C：Consistent 一致性** 事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
- **I：Isolation 隔离性** 如果有多个事务并发执行，同时操作一批数据，每个事务作出的修改必须与其他事务隔离，隔离性越强，即看不见别的事务对数据的修改，同时性能越低；
- **D：Duration 持久性** 即事务完成后，对数据库数据的修改被持久化存储。

## MVCC实现原理

多版本并发控制（MVCC）可以解决读-写并发冲突，提高并发性能。

简单来说，MVCC就是存储了同一条数据的不同历史版本链，不同事物可以访问不同的数据版本（版本快照）（适合读已提交和可重复读）

**当前读和快照读：**

- **当前读：**就是读取记录的当前最新版本，其他事物不能修改记录(增删改查和`select...for update/ lock in share mode`，即加锁)
- **快照读：** 读取MVCC版本链中的某个快照版本，不需要加锁

### 隐藏字段

- `DB_TRX_ID`：创建或者修改的数据的事务ID
- `DB_ROLL_PTR`：回滚指针，指向记录的上一个版本（在undo log中）

多版本数据链使用UNDO（回滚）日志实现，回滚日志存储了修改值的记录的原值（旧版本）

### 版本链

在修改数据的时候，

MySQL除了执行redo log（物理日志）和bin log（逻辑日志）的两阶段提交，还会记录一个undo log，用于事务回滚；

MVCC的版本链就是在undo log上形成的；

### 版本快照

**Read View 读视图**

读视图是事务进行快照读产生的读视图，记录并维护系统当前活跃事务的id数组（事务先后顺序通过事务id大小判断）

- **读已提交：**ReadView会在事务中的每一个SELECT语句查询发送前生成
- **可重复读：**ReadView会在事务的第一个SELECT语句查询发送前生成，且之后的SELECT都是基于这个ReadView

### 快照生成

某个事务进行快照读时可以读到哪个版本的数据，ReadView有一套算法：

**当查询发生时生成ReadView，查询操作沿着undo log链表从最新版本向老版本遍历**

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master8485522-d5afd5fcad183f18.png)

- **绿色范围可以访问（delete_flag也不应为true，否则这个版本是已经被删除的）**
- **浅绿色范围只能访问自己修改的未commit版本**
- **蓝色范围不允许访问**

**总结只有当前事务修改的未commit版本和所有已提交事务版本允许被访问**

**注意UPDATE操作是基于当前读的值进行修改，而不是视图**

## 三大日志

- bin log：逻辑日志
- redo log：物理日志
- undo log：逻辑日志

### bin log

**binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。**

**binlog是mysql的逻辑日志，并且由Server层进行记录**，使用任何存储引擎的mysql数据库都会记录binlog日志。

- 逻辑日志：可以简单理解为记录的就是sql语句。
- 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更，即数据最终的+1-1的原始逻辑（不包含向where那样定位用的逻辑）。

binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

**应用场景：**

- 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。
- 数据恢复：通过使用mysqlbinlog工具来恢复数据。

### redo log

redo log包括两部分：

- 内存中的日志缓冲(redo log buffer)
- 磁盘上的日志文件(redo log file)。

**WAL(Write-Ahead Logging) 技术：**

**mysql每执行一条DML语句，先将记录写入`redo log buffer`，后续某个时间点再一次性将多个操作记录写到`redo log file`。**

**redo log实际上记录数据页的变更，即物理日志**，实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志:

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-6db2466f157a91021b28f70adbe79791_r.jpg)



### undo log

undo log也是MVCC(多版本并发控制)实现的关键

**undo log是逻辑日志，一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。**

MVCC的版本链就是在undo log上

## 两阶段提交

假设执行一条SQL语句：

1. 写入redo log，处于prepare状态
2. 写bin log
3. 修改redo log，状态为commit

**原因：**

- 先写redo log后写bin log，若中间系统崩溃，事务有效，数据写入正常，但基于bin log做数据恢复和主从复制缺少该事务，数据不一致
- 先写bin log 后写redo log，若中间系统崩溃，该事务无效，但基于bin log做数据恢复和主从复制会多出该事务，数据不一致

**崩溃恢复：**

- redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；

- 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：

  - 是，则提交事务；

  - 否，回滚事务。

    由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。

## 如何保证事务四大特性

- **原子性**

  undo log，使得事务可以rollback

- **持久性**

  redo log，数据写入时先记录在redo log(物理日志)，在刷入磁盘

- **隔离性**

  读写锁+MVCC

  - **读未提交：**不加锁，会产生脏数据
  - **读已提交：**读不加锁，写数据加写锁，MVCC会在事务每次查询时生成Read View，不会产生间隙锁，会出现不可重复读
  - **可重复读：**读不加锁，写数据加写锁，MVCC仅在事务第一次查询时生成Read View，会产生间隙锁
    - 可重复读隔离级别下如何解决幻读：
      - 快照读：MVCC版本链解决幻读
      - 当前读（增删改都是当前读）：间隙锁
  - **串行化：** 读加读锁，写加写锁，事务串行执行

- **一致性**

  通过原子性、持久性、隔离性

## 悲观锁/乐观锁

**悲观锁：**

顾名思义，就是对于数据的处理持悲观态度，总认为会发生并发冲突，获取和修改数据时，别人会修改数据。所以在整个数据处理过程中，需要将数据锁定。

悲观锁的实现，通常依靠数据库提供的锁机制实现，比如mysql的排他锁，select .... for update来实现悲观锁。

**乐观锁：**

顾名思义，就是对数据的处理持乐观态度，乐观的认为数据一般情况下不会发生冲突，只有提交数据更新时，才会对数据是否冲突进行检测。

如果发现冲突了，则返回错误信息给用户，让用户自已决定如何操作。

乐观锁的实现不依靠数据库提供的锁机制，需要自已实现，实现方式一般是记录数据版本，一种是通过版本号，一种是通过时间戳。

给表加一个版本号或时间戳的字段，读取数据时，将版本号一同读出，数据更新时，将版本号加1。

当我们提交数据更新时，判断当前的版本号与第一次读取出来的版本号是否相等。如果相等，则予以更新，否则认为数据过期，拒绝更新，让用户重新操作。



**乐观锁是基于程序实现的，所以不存在死锁的情况，适用于读多的应用场景。如果经常发生冲突，上层应用不断的让用户进行重新操作，这反而降低了性能，这种情况下悲观锁就比较适用。**

## 数据库三大泛式

- 第一范式（1 NF）：字段不可再拆分。
- 第二范式（2 NF）：表中任意一个主键或任意一组联合主键，可以确定除该主键外的所有的非主键值。
- 第三范式（3 NF）：消除传递依赖，在任一主键都可以确定所有非主键字段值的情况下，不能存在某非主键字段 A 可以获取 某非主键字段 B。



## join/union

- `inner join` 查交集数据

  ```mysql
  SELECT 
  	emp.name, 
  	emp.gender, 
  	dept.dname 
  FROM 
  	emp 
  	INNER JOIN dept ON emp.dep_id = dept.did;
  ```

- `outer join`

  - `left outer join`：查A表所有数据和AB交集部分数据，左表数据一定有，右表数据可以为null
  - `right outer join`：查B表所有数据和AB表交集部分数据，右表数据一定有，左表数据可以为null

- **自连接：**自己连接自己，相当于对两张一样的表进行查询，但必须起别名

- **联合查询：**

  - `union all` 直接合并所有数据

  - `union` 会将数据去重后合并

    ```mysql
    -- 将薪资低于5000的员工,和年龄大于50岁的员工全部查询出来
    SELECT * FROM emp WHERE salary < 5000
    UNION ALL -- 添加ALL将不合并重复记录
    SELECT * FROM emp WHERE age > 50;
    ```

## IN和EXISTS的区别

- `IN`：IN先把括号里的子表结果集查出来，然后遍历这个临时表，找到外表数据；相当于在子表中执行外表查询
- `EXIST`：EXIST先查找外表，逐条带入子表查询条件进行判断

**适合场景：**

- `IN`适合外表大，子表小
- `EXIST`适合外表小，子表大

# 【操作系统】

## 同步、异步、阻塞、非阻塞

**同步：**当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。

**异步：**当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

**阻塞：**是指调用结果返回前，当前线程会被挂起，即阻塞。

**非阻塞：**是指即使调用结果没返回，也不会阻塞当前线程。

## 线程和进程

**进程：**进程是操作系统进行资源分配和调度的基本单位；计算机中一个程序就是一个进程，程序的生命周期就是进程的生命周期

**线程：**线程是进程的一个执行单元，也是进程内部的调度实体，是比进程更小的能独立运行的基本单位；也被称为轻量级进程，一个进程

**区别：**

- **进程是资源分配的最小单位**，线程是**CPU调度的最小单位**；一个进程在其执行的过程中可以产生多个线程
- 创建进程和撤销进程，系统都要为之分配或回收资源，开销远大于创建或撤销线程时的开销
- 不同进程地址空间相互独立，同一进程内的线程共享同一地址空间；进程只能看到自己的线程
- 进程间相互独立，不会相互影响，同一进程中的不同线程可能相互影响，一个线程挂掉可能导致整个进程挂掉

## 为什么需要线程

进程可以使多个程序并发执行，以提高资源的利用率和系统的吞吐量，但是其带来了一些缺点：

- 进程在同一时间只能干一件事情
- 进程在执行的过程中如果阻塞，整个进程就会被挂起，即使进程中有些工作不依赖当前等待的资源，仍然不会执行

基于以上的缺点，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时间和空间开销，提高并发性能

## 进程状态转换

![进程状态图转换图](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterstate-transition-of-process.png)

**创建状态(new)** ：进程正在被创建，尚未到就绪状态。

**就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。

**运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。

**阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。

**结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。



# 【计网】

## OSI七层模型

- **物理层：**
  - 解决两个硬件之间怎么通信的问题，主要作用是传输比特流；
  - 数据称为比特
- **数据链路层：**
  - 通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路
  - 数据称为帧
- **网络层：**
  - 通过路由选择算法，为报文（该层的数据单位，由上一层数据打包而来）通过通信子网选择最适当的路径
  - 这一层定义的是IP地址，通过IP地址寻址，所以产生了IP协议
  - 数据称为IP报文
- **传输层：**
  - 监控数据传输服务的质量（丢包重传），保证报文的正确传输
- **会话层：**
  - 虽然已经可以实现给正确的计算机，发送正确的封装过后的信息了。但我们总不可能每次都要调用传输层协议去打包，然后再调用IP协议去找路由，所以我们要建立一个自动收发包，自动寻址的功能。于是会话层出现了：它的作用就是建立和管理应用程序之间的通信。
- **表示层：**
  - 表示层负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。
- **应用层：**
  - 应用层是计算机用户，以及各种应用程序和网络之间的接口，其功能是直接向用户提供服务，完成用户希望在网络上完成的各种工作

## TCP五层模型

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20210920130513026.png)

### 物理层

> **物理层确保原始的数据可在各种物理媒体上传输**

物理连接两台计算机，在计算机之间通过高低电频传送0，1电信号（比特流）

### 数据链路层

> **数据链路层在不可靠的物理介质上提供可靠的传输**
>
> 基本数据单位称为帧

- **以太网协议：**

  数据链路层采用以太网协议，数据包称为帧，由表头(Head)和数据(Data)两部分组成组成。

  帧大小一般为64-1518字节，较大数据会分成多个帧传送。

  表头大小固定18字节，发送者(SMAC)、接受者(DMAC)和帧大小等数据

- **MAC地址：** 设备物理寻址，连入网络的设备都会有网卡接口，每个网卡有一个唯一地址，这个地址就叫做 MAC 地址

  MAC地址 由 48 个二进制位所构成，在网卡生产时就被唯一标识了

- **广播与ARP协议：**

  在同一个**子网**中，计算机 A 要向计算机 B 发送一个数据包，这个数据包会包含接收者的 MAC 地址。

  当发送时，计算机 A 是通过**广播**的方式发送的，这时同一个子网中的计算机 C, D 也会收到这个数据包的，然后收到这个数据包的计算机，会把数据包的 MAC 地址取出来，与自身的 MAC 地址对比，如果两者相同，则接受这个数据包，否则就丢弃这个数据包。

  **ARP协议：** 地址解析协议，ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议

### 网络层 

> **网络层负责对子网间的数据包进行路由选择，建立设备到设备的通信**
>
> 基本数据单位为IP数据报

- **IP协议：** IP地址用于网络寻址

  IP 地址由 32 位的二进制数组成，一般用点分十进制表示，地址范围为0.0.0.0~255.255.255.255

  IP地址的二进制位数被划分为两部分（不固定），高位为网络部分，低位为主机部分；相同网络部分称为处于同一子网中

  **子网掩码**用以划分IP地址，其高位（网络部分）全为1，低位（主机部分）全为0，IP地址与子网掩码做与运算的结果即为网络部分

  > 192.168.43.1和192.168.43.2
  >
  > 子码掩码都为255.255.255.0
  >
  > 把IP与子码掩码做AND运算，可以得到他们都为192.168.43.0，进而他们处于同一个子网中

- **ARP协议：** 同一子网的两台设备，当广播到达子网后，通过ARP协议得到具体设备的MAC地址

  主机发送信息时，将包含目标IP地址的ARP请求**广播**到局域网络上的所有主机，并接收返回消息，以此确定目标的物理地址；

  收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。

  **当主机A和主机B不在同一网段时，数据包会交给网关处理**

  1. 主机A就会先向**网关**发出ARP请求，ARP请求报文中的目标IP地址为网关的IP地址。

  2. 网关处理数据包，返回主机A它需要的报文

     - 如果网关没有主机B的ARP表项，网关会广播ARP请求，目标IP地址为主机B的IP地址，当网关从收到的响应报文中获得主机B的MAC地址后，就可以将报文发给主机B；

     - 如果网关已经有主机B的ARP表项，网关直接把报文发给主机B。

- **路由选择：** 网络层通过相应的控制算法给出分组数据转发的最优路径

### 传输层

> **建立端口到端口的通信**
>
> 基本数据单位为TCP报文、UDP报文

- TCP协议：可靠传输
- UDP协议：不可靠传输

### 应用层

> 为操作系统或网络应用程序提供访问网络服务的接口
>
> 基本数据单位为各种协议的报文

- 数据传输基本单位为报文；
- 包含的主要协议：
  - FTP（文件传送协议）
  - Telnet（远程登录协议）
  - DNS（域名解析协议）
  - SMTP（邮件传送协议）
  - POP3协议（邮局协议）
  - HTTP协议（Hyper Text Transfer Protocol）

## TCP

**主要特点：**

1. TCP是面向连接的运输层协议；

   所谓面向连接就是双方传输数据之前，必须先建立一条通道，例如三次握手就是建议通道的一个过程，而四次挥手则是结束销毁通道的一个其中过程。

2. TCP连接点对点的

3. TCP提供可靠的传输服务。

   传送的数据无差错、不丢失、不重复、按序到达；

4. TCP提供全双工通信。

   允许通信双方的应用进程在任何时候都可以发送数据，因为两端都设有发送缓存和接受缓存；

5. 面向字节流。

   虽然应用程序与TCP交互是一次一个大小不等的数据块，但TCP把这些数据看成一连串无结构的字节流，它不保证接收方收到的数据块和发送方发送的数据块具有对应大小关系，例如，发送方应用程序交给发送方的TCP10个数据块，但就受访的TCP可能只用了4个数据块就把收到的字节流交付给上层的应用程序，但字节流完全一样。

**可靠性原理：**

可靠传输有如下两个特点:

- 传输信道无差错,保证传输数据正确;
- 不管发送方以多快的速度发送数据,接收方总是来得及处理收到的数据;

1. 首先，采用三次握手来建立TCP连接，四次挥手来释放TCP连接，从而保证建立的传输信道是可靠的。
2. 其次，TCP采用了连续ARQ协议（回退N，Go-back-N；超时自动重传）来保证数据传输的正确性，使用滑动窗口协议来保证接方能够及时处理所接收到的数据，进行流量控制。
3. 最后，TCP使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制，避免网络拥塞。

## UDP

（１）UDP是无连接的传输层协议；

（２）UDP使用尽最大努力交付，不保证可靠交付；

（３）UDP是面向报文的，对应用层交下来的报文，不合并，不拆分，保留原报文的边界；

（４）UDP没有拥塞控制，因此即使网络出现拥塞也不会降低发送速率；

（５）UDP支持一对一、一对多、多对多的交互通信；

（６）UDP的首部开销小，只有８字节

## TCP和UDP的区别

(1)TCP是可靠传输,UDP是不可靠传输;

(2)TCP面向连接,UDP无连接;

(3)TCP传输数据有序,UDP不保证数据的有序性;

(4)TCP不保存数据边界,UDP保留数据边界;

(5)TCP传输速度相对UDP较慢;

(6)TCP有流量控制和拥塞控制,UDP没有;

(７)TCP是重量级协议,UDP是轻量级协议;

(８)TCP首部较长2０字节,UDP首部较短８字节;

## TCP三次握手

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-2a54823bd63e16674874aa46a67c6c72_r.jpg)

**seq:自己的数据包序号，ack：希望接受到的对方的数据包序号**

**刚开始客户端处于closed状态，服务端处于listen状态：**

1. **第一次握手：**客户端->服务端

   客户端给服务端发送SYN报文，初始化客户端ISN=x，置报文：seq=x

   **客户端处于SYN_SEND状态**

   

2. **第二次握手：**服务端->客户端

   服务端收到客户端的 SYN 报文后会以自己的SYN+ACK报文作为应答，初始化服务端ISN=y，置报文：seq=y, ack=x+1

   **服务端确认：客户端发送正常，服务端接收正常**

   **服务端处于SYN_RCVD状态**

   

3. **第三次握手：**客户端->服务端

​		客户端收到服务端的SYN+ACK报文后，

​		**客户端确认：客户端发送正常，客户端接收正常；服务端接收正常，服务端接收正常**

​		**客户端进入established状态，此时客户端已经可以发送数据**

​		客户端回复服务端ACK报文，置报文：seq=x+1,ack=y+1

​		服务端接收到服务端的ACK报文，

​		**服务端确认： 客户端接收正常，服务端发送正常**

​		**服务端进入established状态**

## 三次握手的作用

1、确认双方的接受能力、发送能力是否正常。

2、指定自己的初始化序列号，为后面的可靠传送做准备。

## 为什么三次握手

TCP协议要建立可靠的连接，就需要保证，对于接收方与发送方双方，都需要确认四点：我方发送正常，我方接收正常；对方发送正常，对方接收正常

1. 第一次握手，接收方确认：对方发送正常，我方接收正常
2. 第二次握手，发送方确认：对方发送正常，对方接收正常；我方发送正常，我方接收正常。发送方进入established状态（这也是为什么第三次握手时发送方可以携带数据）
3. 第三次握手，接收方确认：对方接收正常，我方发送正常，也进入established

## TCP四次挥手

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-92888df73d4608c0a1970c5032612c48_r.jpg)

**刚开始双方都处于established状态，假设客户端先发起关闭请求：**

1. **第一次挥手**

   客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。

   

2. **第二次挥手**

   服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。

   客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态

   

3. **第三次挥手**

   等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态；

   

4. **第四次挥手**

   客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态；

   服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。

   客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

## 为什么要四次挥手

**TCP是全双工通信，既可以发送数据也可以接收数据，所以关闭连接，双方都需要确认，己方不需要发送和接收，对方不需要发送和接收**

****

- 客户端发送FIN，自己不再发送
- 客户端接收ACK，对方不再接收
- 客户端接收FIN，对方不再发送
- 客户端发送ACK，自己不再接收

****

- 服务端接收FIN，对方不再发送
- 服务端发送ACK，自己不再接收
- 服务端发送FIN，自己不再发送
- 服务端接收ACK，对方不再接收

****

- 客户端发送自己的FIN，确认并告知服务端自己不再发送
- 客户端接收服务端的ACK，确认服务端不再接收
- 第二次挥手和第三次挥手中间，是服务端处理和接收数据的时间
- 服务端发送自己的FIN，确认并告知客户端自己不再发送
- 服务端接收客户端的ACK，确认客户端不再接收

**但是三次挥手是可行的，服务端的ACK和FIN可以打包一起发送**

## TCP流量控制

**为什么要流量控制：**

双方在通信的时候，收发双方速率应当步调一致。

如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里，会**缓存溢出**

**滑动窗口：**

- 接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为**接收窗口**大小，用变量来表示接收窗口的大小
- 发送方收到之后，便会调整自己的发送速率，也就是调整自己**发送窗口**的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生

## TCP拥塞控制

# 【Redis】

## Redis线程模型

### Redis为什么是单线程

Redis网络事件处理器是基于文件事件分派器实现的，这个文件事件处理器是单线程的，所以Redis是单线程的

### 文件事件

![640](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640.png)

### 构成组件

- 多个socket
- I/O多路复用程序
- 文件事件分派器
- 命令请求处理器
- 命令回复处理器
- 连接应答处理器
- 时间处理器(做定时用)

### I/O多路复用的实现

![640 (1)](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640%20(1).png)

### 文件事件处理器

- 连接应答处理器

  当Redis初始化时，程序会将连接应答处理器与服务端监听套接字的AE_READABLE事件关联起来，当有客户端通过socket连接服务端时，套接字就会产生AE_READABLE事件，引发连接应答处理器执行，并执行相应的套接字应答操作。

- 命令请求处理器

  当一个客户端通第一步通过socket与服务端连接成功后，服务端将会把该socket的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务端发起命令请求时，如 get xxx，set xxx,套接字就会产生AE_READABLE事件，关联的命令请求处理器就会被执行

- 命令回复处理器

  当服务端需要给客户端响应时，服务端会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联，当客户端准备好接受响应数据时，就会触发AE_WRITABLE事件，执行关联的命令回复处理器的程序，执行对应的套接字写入操作，当数据写入完毕，就会将客户端套接字的AE_WRITABLE事件和命令回复处理器解绑，但是客户端套接字的AE_READABLE事件还是会和命令请求处理器关联。

### 完整的客户端与服务端交互流程

![640 (2)](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640%20(2).png)

**客户端与Redis通信的一次流程：**

server初始化后，在server_socket上注册`AE_READABLE`事件，并与连接应答处理器关联。

1. 客户端请求与服务端建立连接：server收到`AE_READABLE`事件，通过文件事件分派器，找到关联的连接应答处理器，执行应答程序，并且在客户端的socket上注册`AE_READABLE事件`，并与命令请求处理器关联。
   - 通过文件事件分派器，找到连接应答处理器
   - 在客户端的socket上注册`AE_READABLE`事件，并将事件关联命令请求处理器
2. 客户端发起命令请求：如`set a 1`, server会收到`AE_READABLE`事件，通过文件事件分派器，找到关联的命令请求处理器，在内存中执行命令(命令请求处理器从socket中读出key和value，在内存中完成key和value的设置)，并在客户端的socket上注册`AE_WRITABLE`事件，并与命令回复处理器绑定。
   - 通过文件事件分派器，找到命令请求处理器
   - 在内存中执行命令
   - 在客户端的socket上注册`AE_WRITEABLE`事件，并将事件关联请求回复处理器
3. 客户端告诉server自己准备好接受响应数据了：server会收到`AE_WRITABLE`事件，通过文件事件分派器，找到关联的命令回复处理器，将数据写入socket，写入完毕，再将`AE_WRITABLE`与命令回复处理器解绑。
   - 通过文件事件分派器，找到命令回复处理器
   - 将数据写入socket
   - 将`AE_WRITABLE`事件与命令回复处理器解绑

## 为什么Redis单线程且并发响应效率这么快

- 非阻塞I/O多路复用模型，只有调用select、poll、epoll等函数时才会阻塞，收发客户消息不会阻塞，可以充分利用整个线程
- 纯内存操作
- 单线程模式（因为文件事件分派器是单线程的），避免了不必要的上下文切换及竞争条件；也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 数据结构简单，对数据操作也简单，不需要像关系型数据库一样维护复杂的数据结构

## Redis数据类型以及使用场景

- `string`：

  基本数据类型，普通kv操作，

  - 使用场景有很多，比如以userId为`key`，验证码为`value`，设置过期时间做一个验证码功能

- `hash`：

  类似map的一种结构`<hash,key,value>`，一个`hash`对应了一个`<key,value>`的`map`集合；

  - 电商支付项目中，我使用这个数据结构来存放购物车信息，就以userId为`hash`，商品id为`key`，购物车商品对象的json字符串为`value`写入Redis；

    查询购物车的时候就以userId为`hash`查出所有的`<key,value>`键值对，拿到购物车里的所有商品信息

- `list`：

  有序列表，可以按照插入顺序排序，添加元素到列表头部或尾部

  - 在论坛项目中，我使用一个用户的userId为`key`，他粉丝们的userId为`value`，实现了一个粉丝功能
  - Redis 的 lpush + brpop 命令组合即可实现阻塞队列，生产者客户端是用 lpush 从列表左侧插入元素，多个消费者客户端使用 brpop 命令阻塞式的“抢”列表尾部的元素，多个客户端保证了消费的负载均衡和高可用性。

- `set:`

  无序集合，自动去重

  - 一个用户对娱乐、体育比较感兴趣，另一个可能对新闻感兴趣，这些兴趣就是标签，有了这些数据就可以得到同一标签的人，以及用户的共同爱好的标签，这些数据对于用户体验以及曾强用户粘度比较重要

- `sorted set`

  去重且可以排序，写进去的时候给一个分数，他就会根据分数排序

  - 论坛项目中，文章根据热度推送功能就是使用这个数据结构实现的，每天定时更新set集合中热度最高的前10篇文章，实现文章在首页的推送；然后文章每次产生点击时，都会对热度+1

## Redis持久化

持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。Redis 提供了两种持久化方式：RDB（默认）和 AOF。

**RDB**

RDB 是 Redis DataBase 的缩写。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即 Snapshot 快照存储，对应产生的数据文件为 dump.rdb，通过配置文件中的 save 参数来定义快照的周期。核心函数：rdbSave（生成 RDB 文件）和 rdbLoad（从文件加载内存）两个函数。

**AOF**

AOF 是 Append-only file 的缩写。Redis会将每一个收到的写命令都通过 Write 函数追加到文件最后，类似于 MySQL 的 binlog。当 Redis 重启是会通过**重新执行文件中保存的写命令**来在内存中重建整个数据库的内容。

每当执行服务器（定时）任务或者函数时，flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：

- WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件；
- SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。

**RDB 和 AOF 的区别：**

![image-20230413090522037](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230413090522037.png)

- **RDB的优点：**
  - 体积更小：相同的数据量rdb数据比aof的小，因为rdb是紧凑型文件
  - 恢复更快：因为rdb是数据的快照，基本上就是数据的复制，不用重新读取再写入内存
  - 性能更高：父进程在保存rdb时候只需要fork一个子进程，无需父进程进行其他io操作，也保证了服务器的性能。
- **AOF优点：**
  - 数据保证：我们可以设置fsync策略，一般默认是everysec，也可以设置每次写入追加，所以即使服务死掉了，咱们也最多丢失一秒数据

## 分布式锁

**1、加锁**

使用setnx来加锁。key是锁的唯一标识，按业务来决定命名，value这里设置为test。

```java
setnx key test
```

当一个线程执行setnx返回1，说明key原本不存在，该线程成功得到了锁；当一个线程执行setnx返回0，说明key已经存在，该线程抢锁失败；

**2、解锁**

有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程可以进入。释放锁的最简单方式就是执行del指令。

```java
del key
```

释放锁之后，其他线程就可以继续执行setnx命令来获得锁。

**3、锁超时**

锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住，别的线程北向进来。

所以，setnx的key必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一段时间后自动释放。setnx不支持超时参数，所以需要额外指令

```*java
expire key 30
```

****

通过上述setnx 、del和expire实现的分布式锁还是存在着一些问题。

**1、SETNX 和 EXPIRE 非原子性**

假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。

**解决措施:**

由于setnx指令本身是不支持传入超时时间的，而在Redis2.6.12版本上为set指令增加了可选参数, 用法如下：

```java
SET key value [EX seconds][PX milliseconds] [NX|XX]
```

- EX second: 设置键的过期时间为second秒；
- PX millisecond：设置键的过期时间为millisecond毫秒；
- NX：只在键不存在时，才对键进行设置操作；
- XX：只在键已经存在时，才对键进行设置操作；
- SET操作完成时，返回OK，否则返回nil。

**2、锁误解除**

如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

**解决办法：**

在del释放锁之前加一个判断，验证当前的锁是不是自己加的锁。

具体在加锁的时候把当前线程的id当做value，可生成一个 UUID 标识当前线程，在删除之前验证key对应的value是不是自己线程的id。

还可以使用 lua 脚本做验证标识和解锁操作。

**3、超时解锁导致并发**

如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。

A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：

- 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
- 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

**4、不可重入**

当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

**5、无法等待锁释放**

上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

- 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
- 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

## Redis实现消息队列

通过Redis使用List作为队列，RPUSH生产消息,LPOP消费消息

- 没有等待队列里有值就直接消费

  - `BLPOP testlist 30` 阻塞直到队列有消息或者超时

- 只能供一个消费者消费

  - `pup/sub`：主体订阅者模式，pub发送消息，订阅者sub接收消息

    订阅者可以订阅任意数量的频道，即可实现多消费者消费同一个队列的消息

    **缺点：** 消息发布无状态，无法保证可达（发送消息时消费者宕机，重新上线无法接收到消息），解决此问题必须使用专业的消息队列如kafka

## Redis过期策略

我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。

Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。

过期策略通常有以下三种：

- **定时过期：**

  每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。

  该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

- **惰性过期：**

  只有当访问一个key时，才会判断该key是否已过期，过期则清除。

  该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

- **定期清除：**

  每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
  (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中同时使用了惰性过期和定期过期两种过期策略。

## Redis内存淘汰

定期删除漏掉很多过期key，且这些key不再被访问无法惰性删除，会在内存中堆积过多的key，就需要走内存淘汰机制

内存淘汰策略：

- noeviction：内存不足写入新数据时，新写入操作会报错
- allkeys-lru：内存不足写入新数据时，移除最近最少使用的key
- allekys-random：内存不足写入新数据时，随机删除一个key
- volatile-lru：内存不足写入新数据时，在设置了过期时间的键空间中，移除最近最少使用的key
- volatile-random：内存不足写入新数据时，在设置了过期时间的键空间中，随机删除一个key
- volatile-ttl：当内存不足写入新数据时，在设置了过期时间的键空间里，优先删除最早过期时间的key 

## Redis并发竞争问题

用分布式锁确保同一时间只能有一个系统实例在操作key，别人不允许读和写；且每次要写之前要判断一下当前value的时间戳是否比缓存里的时间戳更新，如果更新就可以写，否则不能用旧的数据覆盖新的数据

![image-20230413101630561](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230413101630561.png)

## 缓存雪崩

**缓存雪崩：** 缓存失效，请求全部走数据库

- Redis挂了

  - 事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
  - 事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
  - 事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。

- 对缓存数据设置相同的过期时间，导致某段时间内缓存失效

  解决方法：给过期时间+一个随机值，减少缓存在同一时间过期

## 缓存穿透

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义

**缓存穿透：请求的数据在缓存大量不命中，导致请求走数据库。**

**解决方案：**

- **校验参数合法性**： 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！

  布隆过滤器：二进制数组（0，1表示是否存在数据）

- 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了

## 缓存与数据库双写一致

**不一致：数据库的数据跟缓存的数据不一致**

**操作缓存的方案：**

- 更新缓存

- 删除缓存

  一般采用删除缓存策略：

  1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更加容易**导致数据库与缓存数据不一致问题。(删除缓存**直接和简单**很多)
  2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现**懒加载**)



数据库与缓存操控的先后顺序：考虑原子性和高并发场景

### 先更新数据库，再删除缓存

正常的情况是这样的：

- 先操作数据库，成功；
- 再删除缓存，也成功；

如果原子性被破坏了：

- 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**。
- 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。

如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：

- 缓存**刚好**失效
- 线程A查询数据库，得一个旧值
- 线程B将新值写入数据库
- 线程B尝试删除缓存，发现没有缓存
- 线程A将查到的旧值写入缓存

> 因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，**而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存**，所有的这些条件都具备的**概率基本并不大**。

### 先删除缓存，再更新数据库

正常情况是这样的：

- 先删除缓存，成功；
- 再更新数据库，也成功；

如果原子性被破坏了：

- 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
- 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。

看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：线程A删除缓存-A更新数据的中间，B进行了查询和写缓存

- 线程A删除了缓存
- 线程B查询，发现缓存已不存在
- 线程B去数据库查询得到旧值
- 线程B将旧值写入缓存
- 线程A将新值写入数据库

所以也会导致数据库和缓存不一致的问题。

**并发下解决数据库与缓存不一致的思路**：

- 将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**。

### 策略对比

我们可以发现，两种策略各自有优缺点：

- 先删除缓存，再更新数据库

  在高并发下表现不如意，在原子性被破坏时表现优异

- 先更新数据库，再删除缓存(`Cache Aside Pattern`设计模式)

  在高并发下表现优异，在原子性被破坏时表现不如意



# 【JVM】

## 垃圾回收

### 垃圾回收算法

- **复制算法**

  把存活对象复制到另一块内存区域，清理掉原来的内存区域里的垃圾

  eden区，survivor-from，survivor-to

- **标记清除算法**

  根据可达性分析标记垃圾，清理掉未标记的垃圾

- **标记整理算法**

  根据可达性分析标记垃圾，清除掉未标记的垃圾，并整理存活对象，去掉内存碎片

![image-20230410191332370](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191332370.png)

### 三色标记法

**三色标记法将对象的颜色分为了黑、灰、白，三种颜色**

- 黑色：该对象已经被标记过了，且该对象下的属性也全部都被标记过了。（程序所需要的对象）
- 灰色：该对象已经被标记过了，但该对象下的属性没有全被标记完。（GC需要从此对象中去寻找垃圾）
- 白色：该对象没有被标记过。（对象垃圾）

**算法流程：**

- 从我们`main`方法的根对象（JVM中称为`GC Root`）开始沿着他们的对象向下查找，用黑灰白的规则，标记出所有跟`GC Root`相连接的对象
- 扫描一遍结束后，一般需要进行一次短暂的STW(Stop The World)，再次进行扫描，此时因为黑色对象的属性都也已经被标记过了，所以只需找出灰色对象并顺着继续往下标记（且因为大部分的标记工作已经在第一次并发的时候发生了，所以灰色对象数量会很少，标记时间也会短很多）
- 此时程序继续执行，`GC`线程扫描所有的内存，找出被标记为白色的对象（垃圾）清除

**存在问题**

1. 浮动垃圾：并发标记的过程中，若一个已经被标记成黑色或者灰色的对象，突然变成了垃圾，此时，此对象不是白色的不会被清除，重新标记也不能从`GC Root`中去找到，所以成为了浮动垃圾，这种情况对系统的影响不大，留给下一次GC进行处理即可。

2. 对象漏标问题（需要的对象被回收）：

   ![image-20230411085237664](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411085237664.png)

   黑色对象引用了一个未被扫描的白色对象，同时灰色对象断开了对白色对象的引用，此时该白色对象将不再被扫描并标记为存活对象。

   1. 有至少一个黑色对象在自己被标记之后指向了这个白色对象
   2. 所有的灰色对象在自己引用扫描完成之前删除了对白色对象的引用

   **解决方法：**

   - CMS：增量更新，破坏条件1，关注引用的新增

     当一个黑色对象增加了对白色对象的引用，CMS会记录下这个引用，相当于将黑色对象变灰，在最后标记的时候,再以这个黑色对象为根,对它的引用进行重新扫描

   - G1：原始快照，破坏条件2，关注引用的删除

     当一个灰色对象取消了对白色对象的引用，G1会记录下这个引用，相当于将这个白色对象变灰，最后标记的时候，再以这个白色对象为根进行扫描

### 如何判断一个对象是否死亡

- 可达性分析算法：

  GC Roots作为初始的存活对象合集，然后从该合集出发，探索所有能够被该合集引用到的对象，并将其加入到该和集中，这个过程称之为标记。 

  最终，未被探索到的对象便是死亡的，是可以回收的。

- 引用计数法：

  为每个对象添加一个引用计数器，用来统计指向该对象的引用个数。 一旦某个对象的引用计数器为0，则说明该对象已经死亡，便可以被回收了。

### 哪些可以作为GC-ROOT

- 虚拟机栈中，线程内部，栈帧中，局部变量表里的局部变量引用的对象

- 方法区中已加载的类的静态变量

- 方法区中常量引用的对象

- JNI（Java Native Interface）指针引用的对象

### 常见的垃圾回收器

- **Serial/Serial Old：** 单线程回收新生代/老年代的复制算法的垃圾回收器
- **Parallel Scavenge/Old：** jdk1.8版本默认的多线程回收新生代/老年代的垃圾回收器
- **ParNew + CMS：** 新生代+老年代组合的垃圾回收器，尽量减少停顿时间
- **G1**

### CMS垃圾回收器

![image-20230410191848063](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191848063.png)

- CMS只回收**老年代**
- CMS关注点是尽可能缩短垃圾回收时用户线程的停顿时间
- CMS垃圾回收期是预处理垃圾回收期，需要有触发阈值，默认阈值是达到92%（因为无法处理浮动垃圾，需要预留空间）
- 步骤：
  - 初始标记：stw，仅标记gc-root
  - 并发标记：进行可达性分析
  - 重新标记：stw，修正因为程序运行导致标记变动的对象
  - 并发清除：清理死亡对象
- **优点：**
  - 并发
  - 延迟低
- **缺点：**
  - 会产生内存碎片
  - 无法处理浮动垃圾（并发清除时如果老年代满了，会进行FULL GC并造成stw）

### G1垃圾回收器

![image-20230410193144489](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410193144489.png)

- G1垃圾回收器将堆空间分成了很多个Region，每个Region存放一些对象
- 逻辑上保留分代模型，Region可以作为新生代Region只存放新生代对象，可以作为老年代Region只存放老年代对象，还有特殊的预留Humongous区可以存放大对象
- G1跟踪各个Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值),在后台维护一个优先列表，每次根据允许的收集时间,优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。从而实现一个相对可控的停顿时间
- G1垃圾回收器也是采用标记-清除算法

### 老年代和新生代GC

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-b41981011abd9cd9a00c90588a8ea113_r.jpg)

- Minor GC

  此时会将S0区与Eden区的对象一起进行可达性分析，找出存活的对象，将它复制到S1区，并清空剩下的区域

- Major GC

  发生在老年代的GC

![image-20230410195120244](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410195120244.png)

### 堆空间/分代模型

![image-20230410191425652](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191425652.png)

新生代：复制算法

老年代：标记清除算法、标记整理算法

## JVM如何加载.class文件

![image-20230410181802264](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410181802264.png)

- **加载**：加载字节码文件到内存
- **校验**：校验.class文件是否符合虚拟机规范
- **准备**：为类分配一定的内存空间，并给里面的类变量（static修饰的变量）分配内存空间和默认的初始值
- **解析**：将符号引用替换为直接引用（在编译的时候一个每个java类都会被编译成一个class文件，但在编译的时候虚拟机并不知道所引用类的地址，所以就用符号引用来代替，而在解析阶段就是为了把这个符号引用转化成真正的地址的阶段）
- **初始化**：执行初始化语句，如静态变量的赋值操作、静态代码的执行；若有父类会先初始化父类

## 双亲委派机制

![image-20230411100010222](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411100010222.png)

![image-20230411095956820](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411095956820.png)

**优点：**

- 通过带有优先级的层级关系可以避免类的重复加载
- 保证Java程序安全稳定运行，Java 核心 API 定义类型不会被随意替换

## JVM运行时数据区

![image-20230411091621486](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411091621486.png)

![Java 运行时数据区域（JDK1.8 之后）](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterjava-runtime-data-areas-jdk1.8.png)

## 对象头

![image-20230411092931188](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411092931188.png)



![image-20230411093204553](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411093204553.png)

对齐填充：对象占用大小应当是8字节的整数倍

## JVM启动参数

```properties
# JVM启动参数不换行

# 设置堆空间最大值最小值
-Xmx4g -Xms4g
# 指定Meta区（方法区）的最大值
-XX:MaxMetaspaceSize=2g

# 指定GC算法，选用G1垃圾回收器，指定停顿时长50ms
-XX:+UseG1GC -XX:MaxGCPauseMillis=50
# 指定GC并行线程数
-XX:ParallelGCThreads=4
# 打印GC日志
-XX:+PrintGCetails -XX:+PrintGCDateStamps
# 指定GC日志文件
-Xloggc:gc.log

```

## 设置堆空间的最大值



## 跨平台/语言无关性

![image-20230410181043737](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410181043737.png)

**跨平台：** java语言编写的.java文件编译成.class文件，然后交给Jvm解析成特定平台的机器指令，从软件层面屏蔽不同操作系统在底层硬件和指令的区别，实现跨平台。

**语言无关性：**同时，Jvm只识别字节码文件，所以其和语言解耦，不仅仅是java语言，其他语言只要能编译成符合jvm规范的字节码文件，就可以在jvm上运行。

## JVM解释执行/JIT

解释执行：通过程序计数器逐行解析字节码文件成本地机器指令来执行

JIT(及时编译器)：对于热点代码，JIT会把热点代码（频繁调用的代码）直接编译成本地机器指令，不需要再逐行解释执行

## 对象一定在堆中间创建吗

几乎所有的对象都在堆中创建

当代码为热点代码，被JIT即时编译优化，如果判断对象无法逃逸出当前方法，并且JVM开启标量替换，就会在栈上分配

![image-20230410185126393](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410185126393.png)

## 排查OOM问题

```properties
# 推荐生产环境开启以下参数
# 当OOM发生时自动dump堆内存信息
-XX:+HeapDumpOnOutOfMemoryError 
# dump堆内存信息存放目录
-XX:HeapDumpPath=/tmp/heapdump.hprof
```

使用Visual VM 查看.hprof文件

## JVM相关命令工具

![image-20230411103328200](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103328200.png)

![image-20230411103345339](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103345339.png)

![image-20230411103607515](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103607515.png)

![image-20230411103621439](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103621439.png)

# 【设计模式】

## 单例模式

> 单例模式涉及一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。
>
> 这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。
>
> **注意：**
>
> - 单例类只能有一个实例。
> - 单例类必须自己创建自己的唯一实例。
> - 单例类必须给所有其他对象提供这一实例。
>
> **实现：**
>
> - 将构造方法私有化，杜绝使用构造器创建实例。
> - 需要自身创建唯一的一个实例且私有化，并提供一个全局访问入口

- **懒汉式**

- **饿汉式**

- **双检锁懒汉式**
- **静态内部类**
- **枚举类**

### Spring中的单例模式

**Spring 中 bean 的默认作用域就是 singleton(单例)的。** 除了 singleton 作用域，Spring 中 bean 还有下面几种作用域：

- **prototype :** 每次请求都会创建一个新的 bean 实例。
- **request :** 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。
- **session :** 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。
- **global-session：** 全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话

### 双检锁懒汉式

利用了volatile修饰符的线程可见性（被一个线程修改后，其他线程立即可见）（避免指令重排），即保证了懒加载，又保证了高性能，所以推荐使用。

public class SingletonDCL {

```java
/**
 * 私有实例，volatile修饰的变量是具有可见性的（即被一个线程修改后，其他线程立即可见）
 */
private volatile static SingletonDCL instance;

/**
 * 私有构造方法
 */
private SingletonDCL() {
}

/**
 * 唯一公开获取实例的方法（静态工厂方法）
 *
 * @return
 */
public static SingletonDCL getInstance() {
    if (instance == null) {
        synchronized (SingletonDCL.class) {
            if (instance == null) {
                instance = new SingletonDCL();
            }
        }
    }
    return instance;
}
```

****

**为什么要双检锁：**

当发现实例为null时，所有线程都会尝试竞争锁

竞争锁成功的线程会尝试创建实例，创建实例成功后让出锁

但是此时其他线程又会去竞争锁，竞争锁后又会尝试创建实例

为了保证实例的唯一性，所以竞争锁成功后还要做一次null判断；如果不为null就不需要再创建了，防止后续竞争锁成功的对象继续尝试创建

****

**为什么要volatile：**

因为` instance = new SingletonDCL()`是非原子操作，分为三步

1. 声明instance变量，在堆中为SingletonDCL实例对象分配内存空间
2. 执行SingletonDCL()的构造方法
3. instance引用变量指向将堆中的对象

这个操作可能会被CPU重排序，造成2，3的执行顺序发生错误

**如果线程A先执行了第三步，还没执行第二步或者执行一半突然被挂起，线程B开始执行，线程B会发现此时instance变量不为null，就会直接返回instance；**

**但是此时instance引用指向的实例对象构造方法执行不完全！很有可能会出现空指针异常**

## 代理模式

> 在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。
>
> 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。

Spring中的AOP就是基于动态代理模式实现

## 工厂模式

> 定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行

Spring使用工厂模式可以通过 `BeanFactory` 或 `ApplicationContext` 创建 bean 对象。

**两者对比：**

- `BeanFactory` ：

  延迟注入(使用到某个 bean 的时候才会注入),相比于`ApplicationContext` 来说会占用更少的内存，程序启动速度更快。

- `ApplicationContext` ：

  容器启动的时候，不管你用没用到，一次性创建所有 bean 。`BeanFactory` 仅提供了最基本的依赖注入支持，`ApplicationContext` 扩展了 `BeanFactory` ,除了有`BeanFactory`的功能还有额外更多功能，所以一般开发人员使用`ApplicationContext`会更多。

  **三个实现类：**

  1. `ClassPathXmlApplication`：把上下文文件当成类路径资源。
  2. `FileSystemXmlApplication`：从文件系统中的 XML 文件载入上下文定义信息。
  3. `XmlWebApplicationContext`：从Web系统中的XML文件载入上下文定义信息。

## 观察者模式



## 模板方法模式

> 模板方法模式是一种行为设计模式，它定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。 模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤的实现方式。

Spring中`jdbcTemplate`等以Template 结尾的对数据库操作的类，它们就使用到了模板模式。一般情况下，我们都是使用继承的方式来实现模板模式，但是 Spring 并没有使用这种方式，而是使用Callback 模式与模板方法模式配合，既达到了代码复用的效果，同时增加了灵活性。

## 适配器模式

# 【JavaWeb】

## Servlet执行流程

1. 客户端服务器向tomcat服务器发送http请求：（地址和参数）
2. tomcat解析web.xml文件，找到与之匹配的url和对应的servlet-name
3. 根据servlet-name找到对应的servlet，对其进行实例化和初始化
4. tomcat执行servlet的service()代码，获取返回数据
5. 通过响应返回servlet生成的响应数据

**servlet不是在tomcat启动的时候实例化的，是在第一次访问servlet时实例化，且在tomcat中有且只有一个**

**在并发环境下：基于单例多线程的形式执行，所有线程共享一个servlet实例**

## Servlet生命周期

- **装载-web.xml**

  java应用程序启动时，tomcat会扫描web.xml，得知当前应用有哪些servlet，装载过程中不会实例化

- **创建-构造方法**

  第一次访问servlet时创建servlet，调用构造方法(Java层面的初始化)

- **初始化-init()**

  创建对象后会马上执行init()，是servlet专门的用于初始化servlet执行资源的初始化

- **提供服务-service()方法**

  接收处理请求

  派生方法：

  - doGet

  - doPost

- **销毁-destory()**

  web应用程序关闭重启时启用该方法进行销毁

## 请求和响应的结构

**HTTP请求：**

- 请求行
- 请求头
- 请求体：只在post请求中存在，get请求会将数据附加在url中

![image-20230422163730299](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230422163730299.png)

**HTTP响应**

![image-20230422163838601](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230422163838601.png)

## 请求转发与响应重定向的区别

**请求转发**

- 请求转发是服务器内部跳转，只会产生一次请求
- 请求转发语句是：request.getRequestDispatcher().forward()

![image-20230422164422046](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230422164422046.png)

****

**响应重定向：**

- 响应重定向是浏览器端跳转，会产生两次请求
- 响应重定向语句是：response.sendRedirect()

![image-20230422164614779](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230422164614779.png)



## stmt和pstmt

- PreparedStatement是预编译的SQL语句，效率高于Statement
- PreparedStatement支持`?`操作符，相对于Statement更加灵活
- PreparedStatement可以防止SQL注入，安全性高于Statement

## JDBC五步骤

- 注册驱动

  ```java
  Class.forName("com.mysql.cj.jdbc.Driver");
  ```

- 获取连接

  ```java
  Connection conn = DriverManager.getConnection(url, username, password);
  ```

- 定义SQL语句

  ```java
  String sql =  "UPDATE ...";
  ```

- 获取执行SQL对象

  ```java
  Statement stmt = conn.createStatement();
  ```

- 执行SQL

  ```java
  stmt.executeUpdate(sql);  
  ```

- 处理返回结果

- 释放资源

# 【Spring】

## IOC

**IOC控制反转，是一种设计理念，要求由第三方来管理和控制对象的创建**

1. 如果用new的方式创建对象，会在业务代码里写很多这样的代码，**如果对象进行了修改，就需要对之前的代码都修改，很难维护；**

   解决这个问题可以使用**工厂模式**统一管理对象的创建和装配

2. 然后如果类似有一个订单业务的对象，需要用到MailService和OrderService两个服务；我们通过面向接口编程的思想，使用**接口接收这两个类的实例，这样可以灵活选择接口的实现，可以用set方法把具体的实现类传给接口；**

   但是随着系统复杂度增长，**各种地方set方法变多后，系统也会变得难以维护，还是要考虑对对象之间的引用关系解耦**

   考虑上述问题，解决办法就是比如用XML文件统一维护各个类的依赖关系，实现一个XML解析器来解析里面的依赖关系并执行类依赖的注入；当需要修改的时候，直接在XML文件里修改就可以

控制反转就是做类似的事情，将对象与对象的引用进行解耦，将对象的创建装配和依赖关系都交给第三方管理。有利于工程维护和代码管理

**DI 依赖注入：** 是IOC设计理念的具体实现，由Spring容器来管理对象的创建和依赖的注入

## AOP

**AOP（Aspect Oriented Programming），面向切面编程，为解耦而生；**

做系统设计时，会按业务功能分解成各个低耦合、高内聚的模块或者说组件；**但有很多组件是和业务无关的，比如日志、事务、权限等，而且这些组件又经常需要融入到具体的业务逻辑当中；**

如果在每一个具体业务逻辑都添加这样的代码，会有冗余和难维护的问题，所以我们需要把这些公共的代码逻辑抽象出来

这种时候可以考虑使用**模板方法**、**装饰器**这些设计模式解决

但是模板方法的公共逻辑全写死在父类，无法按需使用，太死板；装饰器设计模式又要求处理公共逻辑的类去实现业务的接口，也很别扭

**所以最好把公共逻辑代码和业务代码完全隔离，他们之间应该是一个正交的关系，就像一个又一个的切面，垂直切入了业务逻辑**

****

AOP就是实现了这样的功能，是IOC的整个流程新增的一个扩展点

bean的创建过程中有一个步骤对bean进行扩展实现，在BeanPostProcessor的后置处理方法中来实现

## Bean实例化的三种方式

- 使用类构造器实例化
- 使用静态工厂实例化
- 使用实例工厂方式实例化

## scope属性的作用和取值

spring中scope是一个非常关键的概念，简单说就是对象在spring容器（IOC容器）中的生命周期，也可以理解为对象在spring容器中的创建方式。

- `singleton`

  类似单例模式，表明容器中只存在一个实例，所有引用此bean的都是单一实例

  对象运行;只要容器在对象就一直活着
  对象销毁：当应用卸载或者销毁容器时，对象被销毁

- `prototype`

  多例模式，每调用一次getBean都进行实例化，且当对象长时间不用的时候就会被垃圾回收

- `session`

  同一个session（会话）内对象是同一个

- `request`

  同一个请求内对象是同一个

## lazy-init属性的作用

懒加载，设置为true后，只有需要用到这个bean的时候才进行初始化（这样可以减少服务器压力）

## @Autuwired/@Resource

- `@Autowired`

  Spring提供的注解

  Autowired只能通过类型对bean进行匹配

- `@Resource`

  Java官方提供的注解

  Resource允许通过bean的id进行匹配；不在注解中写beanId，会按照属性名匹配；最后才按照类型进行匹配

## Bean注入属性的方式

- 通过set方法注入
- 通过构造函数注入
- 通过p名称空间注入

## AOP五种通知类型

- @Before：前置通知，方法执行前通知
- @Around：环绕通知，包裹方法执行
- @AfterReturning：后置通知，方法正常执行完成进行通知，可以访问到方法的返回值
- @AfterThrowing：异常通知，在方法出现异常时进行通知
- @After：方法执行后通知，无论是否正常执行

@Aspect注解将一个java类定义为切面类
@Pointcut定义一个切入点

## Spring、MVC、Boot

- **Spring是所有应用的基础，提供了IOC和AOP特性**

- SpringMVC是Spring的子项目，用于提供Web支持

  SpringMVC封装了Servlet，简化开发难度，让开发人员无需处理HttpRequest，无需处理IO流，只需要关心业务处理；同时提供了切面封装，可以定义拦截器；IO返回的即是页面显示的，而spring mvc却可以返回一个渲染后页面

  而且MVC提供了@GetMapping, @PostMapping, @RestController等注解，进一步简化了开发。

  同时REST与前后端分离兴起之后，后端返回前端只需要返回数据即可。

- **SpringBoot是Spring体系的敏捷开发框架，通过约定大于配置的方式，提高了开发效率；**

  Spring项目的搭建需要配置很多信息，但是SpringBoot简化了配置，他先定义了一些约定（也就是为很多配置设置了默认值），当我们开发的时候，只需要对需要的配置进行更改，其他部分按照约定的默认值来就行

  所以说搭建一个SpringBoot非常简单，Spring官网也说了，开箱即用，“just run”

## 声明式事务

- 声明式事务利用AOP实现自动提交、自动回滚
- 声明式事务规则：进入方法前打开数据库事务，成功提交，失败（RuntimeException）回滚
- 声明式事务启用方式
  - @Transactional
  - spring配置文件里统一配置

## MVC实现REST风格

- REST（表述性状态传递）：以URL表示要访问的资源

- GET/POST/PUT/DELETE：根据请求分成对应查询、新增、更新、删除操作

  对于同一个url，使用不同的请求方式，服务端中心执行的操作也不一样

- REST风格只响应数据，通常以JSON形式体现

## MVC拦截器作用

# 【集合】

## Collection

- `Collection`：单列集合，一次添加一个数据
  - `List`：接口，添加的元素有序、可重复、有索引
    - ArrayList
    - LinkedList
    - Vector
  - `Set`：接口，添加的元素无序、不重复、无索引
    - HashSet
      - LinkedHashSet
    - TreeSet
  - `Queue`
- `Map`：双列集合，一次添加一对数据

![image-20230421100807972](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230421100807972.png)

## ArrayList扩容

- 空参创建集合，底层创建默认长度为0的数组

- 添加元素时，如果数组已满，调用`grow()`方法

- 添加第一个元素时（此时`minCapacity`为1），底层会创建一个新的长度为10的数组

- 当数组长度存满后，再添加元素，扩容数组

  扩容数组会计算扩容的容量:

  ```java
  int newCapacity = ArraysSupport.newLength(
  	oldCapacity, // 旧容量
      minCapacity - oldCapacity, // 最小需要扩容的容量
      oldCapacity >> 1 // 默认扩容容量为旧容量的一半
  );
  ```

  - 当数组存满后，会创建一个新数组，数组长度是原来的1.5倍
  - 如果一次添加多个元素，1.5倍还放不下，则新创建数组的长度以实际为准

## fail-fast：迭代器并发修改异常

> fail-fast 快速失败，失败就会抛出异常

**fail-fast** 机制是**Java集合**(Collection)中的一种**错误机制**。 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的结构进行了修改（增加、删除），则会抛出**Concurrent Modification Exception**（并发修改异常）。

**原理：**

- `ArrayList`内部持有变量`int modCount`，每次修改都会使其自增，类似版本号
- `Iterator`创建时`int expectedModCount = modCount`，设置期望值为当前ArrayList的版本号，相当于快照
- 迭代器每次迭代，都会检查自己的`expectedModCount`和ArrayList里的`modCount`是否相等，若不相等则抛出`Concurrent Modification Exception`（并发修改异常）

****

如何避免并发修改异常

- 不可以在foreach循环里对元素进行remove/add操作；
- remove可以使用迭代器的remove方法，此方法会更新`expectedModCount`为当前的`modCount`；
- 如果并发操作，需要对Iterator对象加锁；

## fail-safe：CopyOnWriteArrayList

> fail-safe：用安全失败机制的集合容器,在遍历时不是直接在集合内容上访问的,而是先copy原有集合内容,在拷贝的集合上进行遍历
>
> 相当于快照

**CopyOnWriteArrayList：读写分离思想**，实现线程安全，适合用于写多读少的情况

- **写时复制**

  当往容器添加元素时：

  1. 复制一个新容器
  2. 在新容器里添加元素
  3. 将旧容器的引用指向新容器

  **注意：**

  写的时候会添加`ReentrantLock`可重入互斥锁，采用FIFO等待队列管理获取该锁的线程，从而保证写的并发执行；

- **并发读取**

  因为采用写时复制机制，

  1. 当并发读取时，迭代器在创建会采用快照机制获取当前容器的引用（也就是旧容器）；
  2. 后续的读取都是在旧容器上进行的；
  3. 就算此时发生了并发写，集合的容器被替换成了新容器，也不影响迭代器里对旧容器的读取

## Set集合

- **HashSet：**

  底层采用哈希表存储数据，实际上内部数据结构是一个HashMap

  JDK8以前：数组+链表

  JDK8之后：数组+链表+红黑树

  无序、不重复、无索引

  

- **LinkedHashSet：**

  在HashSet的基础上对元素使用了双向链表，**实现有序（存储和取出顺序一致）**

  

- **TreeSet：**

  不重复、无索引，**可排序**

  **底层数据结构是红黑树**

  **排序方法：**

  - 默认排序：按照元素大小从小到大；字符类型按照ascii码
  - JavaBean类实现Comparable接口并重写compareTo方法
  - 构造器接收Comparator接口的的实现类

## TODO-红黑树

**红黑树：**

本质是**以二叉树为基础**，引入**红黑颜色属性**，对概念模型**2-3-4树的实现**（存在2结点、3结点和4结点的B树-平衡多路查找树）；

就是说是一个用二叉树的形式表现的一种平衡多路查找树；

**红黑树的每个结点只存一个数据，但用结点的颜色组合出3结点和4结点**

- **2结点：含有一个元素，用黑色结点表示** 

- **非2结点：黑色结点+红色结点**

  红色结点的意义是与黑色父结点结合，表达2-3-4树中的3，4结点

  - **3结点：**含有两个元素，表现为黑结点+红结点
  - **4结点：**含有三个元素，表现为黑结点+左右两个红结点

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-7adca57aaffb4947da7e98a29e6e0f2d_r.jpg)



**红黑树五条定义：**

1. **结点颜色有红色和黑色**

2. **根结点必为黑色**

   因为无论是2-3-4结点，都是以黑结点+红结点的组合表现的

3. **所有叶子结点都是黑色**

   因为红黑树定义了叶子结点是空结点

4. **任意结点到叶子结点经过的黑色结点数目相同**

   虽然红黑树表现为二叉树，实际上逻辑结构是2-3-4树；观察2-3-4树的高度实际上就是观察黑色结点的高度

   当我们观察红黑树结点的逻辑结构时，只要去掉所有红色结点，因为引入叶子结点为黑结点；所以最终的逻辑结构就是一棵平衡的二叉树；

5. **不会有连续的红色结点**

   因为一个3结点或4结点在二叉树中的高度都是2，红色结点不会连续

## HashMap简介

HashMap 存储的是键值对 key - value，key 具有唯一性，采用了拉链法来处理哈希冲突。

当往 HashMap 中添加元素时，会计算 key 的 hash 值取余得出元素在数组中的的存放位置。

HashMap底层的数据结构在 JDK1.8 中有了较大的变化，

- 1.8以前：数组+链表
- 1.8以后：数组+链表/红黑树

HashMap 是线程不安全的，线程安全可以使用 HashTable 和 ConcurrentHashMap 。
键和值都可存放null，键只能存放一个null，键为null时存放入table[0]。

**HashMap存null的个人理解：**

- **key存null：**key为null时调用`hashcode()`方法计算hash值会报空指针异常，所以直接以node[0]作为null的存放地

- **value为null：**当调用`get()`方法获取到值为null的时候，这个null具有二义性：key不存在/key对应的value为null，这个二义性在hashmap中通过`containsKey()`来判断key存不存在破解；

  **但是，**如果A调用`containsKey()`发现`<key,null>`存在，突然被挂起，线程B删除了`<key,null>`，这时候线程A切换回来调用`get(key)`返回了null，此时就无法确定这个null到底是key不存在还是value为null

  **好在hashmap是线程不安全的，它不需要考虑这个问题，所以HashMap允许存null值**

  **相反的，ConcurrentHashMap需要保证线程安全，所以它就不允许存null值了**

## HashMap参数

- 默认长度16

- 最大长度为2的30次幂

- 默认加载因子0.75

- 树化临界值`数组长度>=64 && 链表长度>=7`

  ```java
  /*源码的写法：*/
  
  /*
   * 链表长度的判断：TREEIFY_THRESHOLD=8
   * 可以看到是链表长度>=7的时候考虑树化，会调用treeifyBin方法
   */
   if (binCount >= TREEIFY_THRESHOLD - 1) { // -1 for 1st
  	treeifyBin(tab, hash);
  }
  /*
   * 这段代码是在treeifyBin(tab, hash)方法里的，也就是先判断链表长度再判断数组长度
   * 链表长度的判断：MIN_TREEIFY_CAPACITY=64
   * 可以看到数组不存在或者数组长度<64的时候并不会选择树化，还是调用resize方法进行扩容
   */
  if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY){
      resize();
  }
  
  ```

- 退化临界值6

- HashMap采用Node数组，Node对象实现了Entry接口，存放`<key,value>`

- jdk1.8的hashmap初始化(new)的时候**只赋值了默认的长度16和加载因子**(有参构造可以修改这两个值，其中长度会自动换算成2的整次幂向上取整)，**不会创建node数组，node数组是在第一次put的时候懒加载创建的**

```java
//HashMap的默认初始长度16
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; 
	
//HashMap的最大长度2的30次幂
static final int MAXIMUM_CAPACITY = 1 << 30;
	
//HashMap的默认加载因子0.75
static final float DEFAULT_LOAD_FACTOR = 0.75f;
	
//HashMap链表升级成红黑树的临界值
static final int TREEIFY_THRESHOLD = 8;
	
//HashMap红黑树退化成链表的临界值
static final int UNTREEIFY_THRESHOLD = 6;
	
//HashMap链表升级成红黑树第二个条件：HashMap数组(桶)的长度大于等于64
static final int MIN_TREEIFY_CAPACITY = 64;
	
//HashMap底层Node桶的数组
transient Node<K,V>[] table;
	
//扩容阈值，当你的hashmap中的元素个数超过这个阈值，便会发生扩容
//threshold = capacity * loadFactor
int threshold;
```

## HashMap为什么长度是2的整次幂

在计算存入结点下标时，会利用 key 的 hsah 值进行取余操作，而计算机计算时，并没有取余等运算，会将取余转化为其他运算。

当n为2次幂时，会满足一个公式：

`(n - 1) & hash = hash % n`

就可以用位运算代替取余运算，计算更加高效。

**解释：**

hashmap默认长度16（二进制10000），16-1=15（二进制01111）

hash & 15，相当于hash中5-32位全部舍弃（任何数&0都是0）（hash是int类型，4字节32位）

也就是最终只保留了hash中的低4位数据，这个值就在数组长度范围内，可以作为散列到的数组下标，这一结果和以数组长度取余的结果是相同的。**这也解释了为什么hashmap数组长度要求是2的整次幂，因为2的整次幂-1的二进制是高位全0低位全1，进行&运算就可以舍弃高位保留低位，起到取余的效果**

**但是这有另一个问题，直接舍弃高位部分以低位部分作为散列位置，很容易导致散列位置聚集，发生hash冲突概率加大，所以在计算hashcode的时候采取了二次hash的方法：将高位掺入低位做一个扰动**

## HashMap哈希值计算

HashMap的哈希值计算采用了两次哈希运算

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

- 第一步：计算key的哈希值，采用key自身的`hashCode()`方法

- 第二步：将key的哈希值h，执行`h^(h>>>16)`

  即将h的高位不变，低位部分改成低位+高位的异或值

**二次哈希运算的原因：**

因为hashmap采用长度为2的n次幂，在计算散列位置的时候，将`hash % n`运算优化为了 `hash & (n-1)`

而hashmap的初始长度为16，也就说初始时的运算时为

`hash & (此处省略28个0)1111`

**在hashmap长度不大的时候，hash高位的数据在运算后全变成0，也就是全部丢失了，没有参与到散列位置的计算，很容易造成元素散列位置的聚集，大大增加了hash冲突的可能性**

对hash值的低位部分采用高位+低位的异或运算，将高位信息掺入低位信息进行扰动，可以分散数据的散列位置，减少哈希冲突，提高性能

****

String常作为key，String要设计成不可变类的好处之一，只需要计算一次hashcode

**String的hashCode()方法：**

```java
public int hashCode() {
    /* private int hash; // Default to 0 */
    int h = hash;
    if (h == 0 && value.length > 0) {
        char val[] = value;
        /* 核心：h = 31 * h + val[i]; */
        for (int i = 0; i < value.length; i++) {
            h = 31 * h + val[i];
        }
        hash = h;
    }
    return h;
}
```

`h = 31 * h + val[i]`：hash值的计算将hash每次乘31再加上char数组元素的ascii码

**个人理解：**

`31 * h = (h * 36) - h = (h << 5) - h` 编译器会自动优化成位运算 

选择31，其一是因为31是个素数，与素数相乘得到的结果比其他方式更容易产生唯一性；

其二是因为31是32-1，32是2的整次幂，31的二进制数是11111，五位二进制数，不仅可以优化成上述的位运算，而且这个数还不是很大（大数相乘要考虑溢出问题）；

17也是素数，但是17没有31刚好是32-1的特性，不能优化成位运算，所以不选择。

## HashMap扩容机制

- hashmap是懒加载，只有在第一次put的时候才会创建数组
- 默认扩容大小为原来的2倍

****

**JDK 1.7以前扩容，条件：**

- 当前存储的数量大于等于阈值
- 发生hash碰撞

**特点：**先扩容再添加，采用头插法

**缺点：**头插法会使链表发生反转，多线程环境下可能会死循环

**扩容后对table的调整：**

容量变成原来的2倍，所有元素下标都需要重新结算，`newIndex = hash (扰动后) & （newLength - 1）`

****

**JDK 1.8以后的扩容，条件：**

- 当前存储的数量大于等于阈值
- 当某个链表长度>=8，但是数组存储的结点数size() < 64时

**特点：**先插入，后判断是否需要扩容，采用尾插法

**缺点：**多线程下，1.8版本会有数据覆盖

**扩容后对table的调整：**

table容量变为2倍，但是不需要像之前一样计算下标，只需要将hash值和旧数组长度相与即可确定位置。

## HashMap在1.7和1.8的不同

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master02f3eff6c97148579b66e30e1d17d84d.png)

JDK1.8主要解决或优化了以下问题：

1. resize 扩容和 计算hash 优化
2. 引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考
3. 解决了多线程死循环问题（头查法改成尾插法），但仍是非线程安全的，多线程时可能会造成数据丢失问题。

## 加载因子为什么是0.75

- 加载因子过高，哈希碰撞概率太大，查询效率降低（因为遍历链表要O(n)）
- 加载因子太低，频繁扩容，降低空间利用率

加载因子是0.75是基于空间利用率和查找效率的折中取值

## 树化阈值为什么是8

首先如果链表过长，会造成查询效率过低，所以转化成红黑树加快查找效率（O(n) -> O(log n)）

其次树化应该是针对异常现象的防御机制，主要是为了防备类似DDOS攻击（短时间内发起大量请求，耗尽服务器的资源，这里就是让hashmap链表拉长，削弱hashmap性能），所以要尽量避免；

作者在源码注释里大致是这样的意思：

- 插入数据时，是否发生哈希碰撞是一个独立随机事件
- 如果hash函数设计的好，散列均匀，发生k次哈希碰撞的概率是一个二项分布，且近似于泊松分布
- 当加载因子为0.75时，泊松分布以λ=0.5入参。
- 作者计算了不同k时的概率P
- 而当k=8时，这个概率已经足够小：6的-8方，所以选取了8的阈值

****

**退化阈值为什么是6**

如果退化阈值也是8的话，当哈希碰撞发生次数在8左右时，会出现链表和红黑树的反复转化，非常浪费性能

## ConcurrentHashMap原理

**ConcurrentHashMap是JUC下线程安全的HashMap容器**

****

**1.7版本：** 使用的分段锁

采用Segment数组+HashEntry数组的形式，大数组包含小数组

每个Segment类似于HashMap的结构，HashEntry数组+链表

Segment继承了`ReetrantLock`，每次加锁锁住一个Segment，也就是锁住一个小HashEntry数组（一个小的hashmap）

![Java 7 ConcurrentHashMap 存储结构](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterjava7_concurrenthashmap.png)

`Segment` 的个数一旦**初始化就不能改变**，默认 `Segment` 的个数是 16 个，你也可以认为 `ConcurrentHashMap` 默认支持最多 16 个线程并发。

****

**1.8版本**

1.8版本ConcurrentHashMap采用锁粒度更小的Node数组+链表/红黑树的模式，更像1.8版本的HashMap；加锁时直接锁在Node上

![Java8 ConcurrentHashMap 存储结构（图片来自 javadoop）](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterjava8_concurrenthashmap.png)

**写入数据时：**

- 桶内为空采用CAS方式自旋写入
- 桶内不为空，采用synchronized锁方式添加到链表/红黑树

**因为Java在1.8版本优化了synchronized关键字：锁升级机制（偏向锁->轻量级锁(自旋锁)->重量级锁），所以性能方面还是有保障的**



## Hashtable和ConcurrentHashMap

- Hashtable与ConcurrentHashMap都是线程安全的Map集合
- Hashtable并发度低，整个Hashtable一把锁，同一时刻指捏那个有一个线程操作它
- 1.8以前ConcurrentHashMap采用分段锁（Segment+数组+链表），1.8以后采用Node数组头结点作为锁，锁粒度更低，并发度更高

# 【JavaSE】

## 面向对象/面向过程

**面向过程：**

面向过程是一种以事件为中心的编程思想，编程的时候把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步一步的具体步骤中再按顺序调用函数。

****

**面向对象：**

面向对象是一种以“对象”为中心的编程思想，把要解决的问题分解成各个对象，**建立对象的目的不是为了完成一个步骤，而是为了描叙某个对象在整个解决问题的步骤中的属性和行为**

## 面向对象三大特性

- **封装：**

  把数据和操作数据的方法封装起来，对数据的访问只能通过已定义的接口

- **继承：**

  继承是从已有类得到继承信息创建新类的过程；提供继承信息的是父类/超类/基类，继承继承信息的是子类

- **多态：**同一类型，表现出多种不同行为

  - 编译时多态（方法重载）
  - 运行时多态（方法重写）

****

## 权限修饰符

| 权限/修饰符  | `public` | `protected` | `default` | `private` |
| :----------: | :------: | :---------: | :-------: | :-------: |
|   同一个类   |   YES    |     YES     |    YES    |    YES    |
|   同一个包   |   YES    |     YES     |    YES    |    NO     |
|  不同包子类  |   YES    |     YES     |    NO     |    NO     |
| 不同包非子类 |   YES    |     NO      |    NO     |    NO     |

- `public`：所有类都可以访问
- `protected`：同一个包下所有类，及其（不同包下）子类可以访问
- `default`：同一个包下可以访问
- `private`：只有同一个类下可以访问

## 重载和重写的区别

- **重载（Overload）**

  方法之间的多态性

  - 函数名相同
  - 参数列表可以不同
  - 返回类型可以不同
  - 访问修饰符可以不同
  - 抛出异常可以不同

- **重写（Override）**

  父类与子类之间的多态性，是子类对父类函数的重新实现

  - 函数名、参数列表、返回值必须与父类一样

  - 子类访问修饰符必须大于父类访问修饰

    （public>protected>default>private）

  - 子类抛出异常不能比父类更宽泛

## 是否可以重写private/static方法

Java 中 static 方法不能被覆盖，因为方法覆盖是基于运行时动态绑定的，而 static 方法是编译时静态绑定的。static 方法跟类的任何实例都不相关，所以概念上不适用。

Java 中也不可以覆盖 private 的方法，因为 private 修饰的变量和方法只能在当前类中使用， 如果是其他的类继承当前类是不能访问到 private 变量或方法的，当然也不能覆盖。

> 静态的方法可以被继承，但是不能重写。
>
> 如果父类和子类中存在同样名称和参数的静态方法，那么该子类的方法会把原来继承过来的父类的方法隐藏，而不是重写。
>
> 通俗的讲就是父类的方法和子类的方法是两个没有关系的方法，具体调用哪一个方法是看是哪个对象的引用；这种父子类方法也不在存在多态的性质。

## 父类无参构造的作用

空构造方法：无参数且不做事

**Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中的无参构造**。

如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super() 来调用父类中特定的构造方法，则编译时将发生错误。

## 创建对象的方式

1. new 对象

2. Class类的newInstance方法，该方法基于反射，调用无参构造器创建对象

   `Class.forName.newInstance()`

3. 使用`clone()`方法

4. 反序列化

## 抽象类和接口的区别

1. 抽象类中可以定义**构造函数**；接口不能定义构造函数
2. 抽象类中可以有**抽象方法和具体方法**；接口中只能有抽象方法（public abstract）
3. 抽象类的**成员权限**不能是private(抽象类中的抽象方法就是为了重写，所以不能是private)；接口只能是public
4. 抽象类中可以有静态方法；接口中不可以有静态方法（JDK 8之后可以）

**JDK 8 中的改变：**

1. **接口中**允许包含**default修饰的带具体实现的方法**，即默认方法
2. 抽象类中可以包含**静态方法**；**接口在JDK 8 之后可以包含**，但只能通过接口调用，且不能包含静态代码块；

## 静态变量和实例变量的区别

**静态变量：** static修饰，属于类变量，存放在方法区；无论创建多少个实例对象，静态变量在内存中有且仅有一个拷贝；静态变量可以实现让多个对象共享内存

**实例变量：**属于某个实例，和对象一起存放在堆中（JVM经JIT优化后可能会栈上分配）需要创建对象

## short=1系列错误

```java
short s1 = 1;
s1 = s1 + 1;
```

s1+1在运算时自动提升表达式的类型为int，将int类型值赋值给shrot类型变量，s1会发生类型转换错误

```java
short s1 = 1;
s1 += 1;
```

`+=`是 Java 语言规定的运算符，Java编译器会对其进行特殊处理，可以正确编译

## Error和Excetion

Error和Excetion都是Throwable的子类

- Error：程序无法处理的系统错误，比如JVM错误，栈溢出等
- Exception：程序可以处理的异常，可以被捕获，被处理
  - RuntimeException：运行时异常，程序应当承担的责任
  - 非RuntimeException：检查时异常，编译器应当承担的责任

![image-20230421100138647](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230421100138647.png)



## Hash冲突解决

- **开放地址法（闭散列）：**

  一旦发生冲突，就寻找下一个空的散列地址；

  ```
  Hi = (H(key) + di) MOD m，其中i=1,2,…,k(k<=m-1)
  H(key)为哈希函数，m为哈希表表长，di为增量序列，i为已发生冲突的次数。
  ```

  - 线性探测法：当前冲突位置为起点，步长为1循环查找
  - 平方(二次）探测法：当前冲突位置为起点，步长di=1^2，-1^2，2^2，-2^2，……
  - 伪随机探测法：当前冲突位置为起点，随机步长循环查找

- **再哈希法**

  构造多个不同的哈希函数，直到不冲突为止

  ```
  Hi=RH1（key） i=1，2，…，k
  ```

- **拉链法（开散列）：**

  将所有哈希地址相同的都链接在同一个链表中 ，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况，hashmap就是基于此方法解决冲突的。

- **建立公共溢出区：**

  将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

****

**拉链法对比开放地址法的优点**

- 拉链法处理冲突简单，且无堆积现象；即非同义词绝不会发生冲突，因此平均查找长度较短
- 拉链法中各链表上的结点空间是动态申请的，适合造表前无法确定表长的情况
- 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。
- 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可

## Integer

1. int 是 Java 的八种基本数据类型之一，而 Integer 是 Java 为 int 类型提供的封装类；
2. int 型变量的默认值是 0，Integer 变量的默认值是 null，这一点说明 Integer 可以区分出未赋值和值为 0 的区分；
3. Integer 变量必须实例化后才可以使用，而 int 不需要。

**Integer 和 int 的比较延伸**：

1. `Integer == int` Integer会自动拆箱，实际上是两个int类型变量比较
2. `Integer.equals(Integer)`：Integer重写了equals方法，会先比较类型再比较值（所以String和Integer比较一定是false）
3. `Integer == Integer`：比较的是地址值

## 包装类型的hashcode方法

- `Integer`

  hashcode为Integer的值

- `String`

  ```java
  hashcode = 31 * h + val[i];
  // 31 * h == (h << 5) - h
  ```

- `Long`

  ```java
  hashcode = value ^ (value>>>32);
  // 前32位和后32位进行异或运算
  // 最后结果就是高位不变，低位是高位和低位的异或结果
  ```

- `Double`

  同Long

- `Character`

  hashcode为字符对应的ASCII值

- `Boolean`

  ```java
  value ? 1231 : 1237;
  ```

## switch语句

**在 switch(expr 1) 中，expr1 只能是一个整数表达式或者枚举常量。**

而整数表达式可以是 int 基本数据类型或者 Integer 包装类型。由于，byte、short、char 都可以**隐式转换为 int**，所以，这些类型以及这些类型的包装类型也都是可以的。

而 long 和 String 类型都不符合 switch 的语法规定，并且不能被隐式的转换为 int 类型，所以，它们不能作用于 switch 语句中。

**不过，需要注意的是在 JDK 7 版本之后 switch 就可以作用在 String 上了。（且实际上是通过hashcode实现）**

## static关键字

（1）静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份；

（2）静态方法：静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字；

（3）静态语句块：静态语句块在类初始化时运行一次；

（4）静态内部类：非静态内部类依赖于外部类的实例，而静态内部类不需要。静态内部类不能访问外部类的非静态的变量和方法；

（5）初始化顺序：静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序

**存在继承关系时的初始化顺序：**

- 父类（静态变量、静态代码块）
- 子类（静态变量、静态代码块）
- 父类（实例变量、普通代码块）
- 父类（构造函数）
- 子类（实例变量、普通代码块）
- 子类（构造函数）

## super关键字

（1）访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。

（2）访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。

（3）this 和 super 不能同时出现在一个构造函数里面，因为 this 必然会调用其它的构造函数，其它的构造函数必然也会有 super 语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。

## transient关键字

对于不想进行序列化的变量，使用 transient 关键字修饰。

transient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化。当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。transient 只能修饰变量，不能修饰类和方法。



## final、finally、finalize

`final`：用于声明属性、方法和类，分别表示属性不可变、方法不可覆盖、被其修饰的类不可继承；

`finally`：异常处理语句结构的一部分，表示总是执行；

`finallize`：Object类的一个方法，在垃圾回收时会调用被回收对象的finalize

## hashcode()和equals()

- **两个对象的 hashcode() 相同，equals() 不一定为 true。**

  因为在散列表中，hashCode() 相等即两个键值对的哈希值相等，然而哈希值相等，并不一定能得出键值对相等；因为有【hash冲突】

- **为什么重写equals方法就要重写hashcode方法**

  重写equals方法必须重写hashcode方法，是为了散列表服务的

  **重写equals方法，说明我们需要用自己的规则来定义两个对象是否相同；通常使用属性值来判断；**

  在使用散列表如HashMap时，会使用hashcode方法来确定散列位置：

  - 如果不重写hashcode方法，默认是使用地址值，会造成自定义规则下的相同对象被散列到不同位置
  - 如果不重写equals方法，发生hash冲突时，判断对象是否为自定义规则下的相同对象就是发生错误（可能会导致本应覆盖结果没有覆盖，直接链上去了）

  并且对于集合判重，使用hashcode方法通常比equals方法效率更高，尽可能确保不同对象拥有不同hashcode，就可以减少使用equals方法判重的次数，提高效率。

**equals方法和hashcode方法的规定：**

1、如果两个对象相等，则 hashCode 一定也是相同的；

2、两个对象相等，对两个对象分别调用 equals 方法都返回 true；

3、两个对象有相同的 hashCode 值，它们也不一定是相等的；

4、因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖；

5、hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。

## &和&&

Java 中 && 和 & 都是表示与的逻辑运算符，都表示逻辑运输符 and，当两边的表达式都为 true 的时候，整个运算结果才为 true，否则为 false。

`&&`：有短路功能，当第一个表达式的值为 false 的时候，则不再计算第二个表达式；

`&`：不管第一个表达式结果是否为 true，第二个都会执行。

除此之外，& 还可以用作位运算符：当 & 两边的表达式不是 Boolean 类型的时候，& 表示按位操作。

## 参数传递

Java 的参数是以值传递的形式传入方法中，而不是引用传递。

当传递方法参数类型为基本数据类型（数字以及布尔值）时，一个方法是不可能修改一个基本数据类型的参数。

当传递方法参数类型为引用数据类型时，实际上传入的是**引用的拷贝**，所以：

- **在方法中修改引用的对象的值**，因为两个引用指向同一对象，所以**成功**
- **在方法中修改引用指向的对象**，仅仅只修改了方法中的引用的指向；对方法外的引用**无影响**

## Math.round

在数轴上向右取整，返回int(float)/long(double)

- `round(-1.5) == -1`

- `round(1.5) == 2` 

`Math.floor()`数轴上向左取整，返回double类型

`Math.ceil()`数轴上向右取整，返回double类型

## 两个二进制数的异或结果

两个二进制数异或结果是这两个二进制数差的绝对值。表达式如下：a^b = |a-b|

因为异或运算按位运算，1-0=0；0-1=1，相当于按位绝对值相减，再按位相加

## 如何实现对象的克隆

（1）实现 Cloneable 接口并重写 Object 类中的 clone() 方法，实现浅克隆；

（2）实现 Serializable 接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深克隆。

## 深克隆和浅克隆的区别

1. **浅克隆：**

   拷贝对象和原始对象的引用类型引用同一个对象。浅克隆只是复制了对象的引用地址，两个对象指向同一个内存地址，所以修改其中任意的值，另一个值都会随之变化，这就是浅克隆。

2. **深克隆：**

   拷贝对象和原始对象的引用类型引用不同对象。深拷贝是将对象及值复制过来，两个对象修改其中任意的值另一个值不会改变，这就是深拷贝（例：JSON.parse() 和 JSON.stringify()，但是此方法无法复制函数类型）。

## Java序列化

对象序列化是一个用于将对象状态转换为字节流的过程，可以将其保存到磁盘文件中或通过网络发送到任何其他程序。从字节流创建对象的相反的过程称为反序列化。而创建的字节流是与平台无关的，在一个平台上序列化的对象可以在不同的平台上反序列化。序列化是为了解决在对象流进行读写操作时所引发的问题。

**什么时候需要序列化：**

（1）当你想把的内存中的对象状态保存到一个文件中或者数据库中时候；

（2）当你想用套接字在网络上传送对象的时候；

（3）当你想通过 RMI 传输对象的时候。

## 泛型如何工作/类型擦除

**泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。**

例如：List\<String> 在运行时仅用一个 List 来表示。这样做的目的，是确保能和 Java 5 之前的版本开发二进制类库进行兼容。

**类型擦除：**

泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除。

在泛型类被类型擦除的时候，之前泛型类中的类型参数部分如果没有指定上限，如 < T > 则会被转译成普通的 Object 类型，如果指定了上限如 < T extends String > 则类型参数就被**替换成类型上限**。

## 通配符

**限定通配符：** 泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误

- `< ? extends T >`：传入类型是T或T的子类
- `< ? super T >`：传入类型是T或T的父类

**非限定通配符**

- `< ? >`：接收任意类型

## 反射

每个类都有一个 Class 对象，包含了与类有关的信息。

当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。

类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。

也可以使用 Class.forName(“com.mysql.jdbc.Driver”) 这种方式来控制类的加载，该方法会返回一个 Class 对象。

反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。

Class 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：

（1）Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段；

（2）Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法；

（3）Constructor ：可以用 Constructor 创建新的对象。

应用举例：工厂模式，使用反射机制，根据全限定类名获得某个类的 Class 实例。

## 反射的优缺点

**优点：**

运行期类型的判断，class.forName() 动态加载类，提高代码的灵活度；

**缺点：**

尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。

（**1）性能开销 ：**

**反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。**因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。

**（2）安全限制 ：**

使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。

**（3）内部暴露：**

由于反射允许代码执行一些在正常情况下不被允许的操作（比如：访问私有的属性和方法，比如破坏单例模式），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。

## 动态代理

> java 动态代理通过反射机制，可在不修改原代码的情况下添加新的功能

**动态代理：**

代理，即调用者不需要跟实际的对象接触，只跟代理打交道（就像买房只通过房地产中介买，买家和卖家解耦；中介可以在买家买房和卖家卖房中间做一些自己的事）

java 动态代理就是通过反射机制实现代理，可以在不修改原代码的情况下添加新的功能。

动态代理的应用：Spring 的 AOP 、加事务、加权限、加日志。

## 如何实现动态代理

- 实现`InvocationHandler`，由它实现`invoke`方法，执行代理函数
- 使用`Proxy`类，创建代理类，关联委托类
- 使用代理类执行代理函数，会调用`invoke`方法，完成代理

```java
/**
 * 日志动态代理类：JDK实现
 **/
publicclass JdkLogProxyHandler implements InvocationHandler {
    private Object targetObject;

    /* 实现invoke方法 */
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println(" jdk dynamic proxy log begin ");
        /* 执行委托类的方法，拿到的是委托类的方法返回值 */
        Object result = method.invoke(targetObject, args);
        System.out.println(" jdk dynamic proxy log end ");
        return result;
    }

    /**
     * 根据委托类动态产生代理类
     * @param targetObject 委托类对象
     * @return 代理类
     */
    public Object createPorxy(Object targetObject){
        this.targetObject = targetObject;
        /* 使用Proxy类创建委托对象 */
        return Proxy.newProxyInstance(targetObject.getClass().getClassLoader()
        ,targetObject.getClass().getInterfaces(),this);
    }
}
```

```java
@Test
void testLogProxy() {
    JdkLogProxyHandler logProxyHandler = new JdkLogProxyHandler();
    /* 获取代理类对象 */
    IService proxy = (IService) logProxyHandler.createPorxy(new ServiceImpl());
    proxy.doAction1();
    System.out.println("############");
    proxy.doAction2();
}
```

## String为何要设置成不可变

1. **实现字符串常量池：**String类型引用指向常量池中的字符串常量，如果String可变，就无法让多个String引用常量池中的同一个字符串了

2. **允许String对象缓存hashcode：**String不可变，hashcode只需要计算一次，具有唯一性，就可以缓存在对象里；考虑到String类型常用于散列表，这样做提高性能

3. **String类型常被多个Java类作为参数，不可变可以保证安全性**

   比如网络地址的url、文件的地址、反射机制需要的参数等，String的改变可能造成很多安全隐患
   
4. **不可变对象的String天然线程安全**

## String/Builder/Buffer

**String：**用于字符串操作，属于不可变类；【补充：String 不是基本数据类型，是引用类型，底层用 char 数组实现的，但char数组使用了private final static修饰，不可被外界访问，引用的数组不可更改，不可被继承，从而实现String的不可变】

**StringBuilder：**与 StringBuffer 类似，都是字符串缓冲区，但**线程不安全**；

**StringBuffer：**也用于字符串操作，不同之处是 StringBuffer 属于可变类，**对方法加了同步锁，线程安全**

**执行效率：StringBuilder > StringBuffer > String**

**toString()方法产生的字符串不会进入常量池**

****

当用String类型来对字符串进行修改时，首先创建一个StringBuilder，其次调用 StringBuilder 的 append() 方法，最后调用 StringBuilder 的 toString() 方法把结果返回。

所以`"a"+"b"`的`"ab"`字符串不会加入常量池

## 字符串常量池

`String str = "i"` ：添加到字符串常量池（如果存在会直接使用常量池中的常量）

`String str = new String("i")` ：分配到堆内存

## String常用方法

indexOf()：返回指定字符的索引。

charAt()：返回指定索引处的字符。

replace()：字符串替换。

trim()：去除字符串两端空白。

split()：分割字符串，返回一个分割后的字符串数组。

getBytes()：返回字符串的 byte 类型数组。

length()：返回字符串长度。

toLowerCase()：将字符串转成小写字母。

toUpperCase()：将字符串转成大写字符。

substring()：截取字符串。

equals()：字符串比较。

## IO流分类

**功能分：**

- 输入流（input）
- 输出流（output）

**类型分：**

- **字节流**（in/out put stream）

  字节流按照字节为单位(8bit)输入输出数据

  - **字节缓冲流**【BufferedInput(Output)Stream】

    缓冲流内部维护字节数组，一次性读取多个字节，减少IO次数

- **字符流**（reader/writer）

  字符流按照字符为单位(16bit)输入输出顺序

  - **字符缓冲流**【BufferedReader(Writer)】

    缓冲流内部维护字符数组，一次性读取多个字符，减少IO次数

![img](https://image.iamshuaidi.com/picture/640.jpeg)

![img](https://image.iamshuaidi.com/picture/image-20210602135829398.png)

## BIO/NIO/AIO区别

**BIO：**

Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。

同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机 1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。

线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。

但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。

**NIO：**

New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。

NIO 是一种同步非阻塞的 I/O 模型，在 Java1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。

NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。

NIO 提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现，两种通道都支持阻塞和非阻塞两种模式。

阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；

非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞 I/O 来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。

**AIO：**

Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。

也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

AIO 是异步 IO 的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。

对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。





# 【面试中的查漏补缺】

## 自我介绍模块

面试官您好！

我叫董萌，来自于太原理工大学，专业是信息与计算科学；

我从大一开始参与了学校的云顶书院技术社团，在那里经历了c语言的编程启蒙，并在大一下决心深耕于Java开发；

我在校成绩还算不错，绩点排名在前30%，拿过院级奖学金和两次学业优秀奖，计算机408基础课和Java课程也保持均分在90分以上；

而在Java方面的学习，平时也是既有视频入门，看书、博客巩固等方式学习；

我本人在社团活动中参与过项目的开发；在大一寒假线上合作进行javaweb项目的小组开发，在大二暑假留校的Spring小组开发项目；目前为止也有在大三进行迭代已有项目和新的比赛项目开发，所以有一定的开发经验；

我对自己的评价是首先是擅长自学，我对计算机基础课的学习和Java的学习都是早于学校课程开设的（事实上计算机网络课程是我这学期开设的，不过我已经通过阅读《自顶向下》这本书完成了初步的学习），而反馈就是这几门课成绩还不错；二是我认为我有一定的团队精神，在我社团项目开发的时候，因为学长刻意的放养操作，大一第一次开发经历过很多困难，也经历过小组成员吵架，我作为组长也是调节小组气氛、和前端副组长熬夜赶项目，最后也是在死线之前完成任务，大二也是作为副组长带低年级的学弟学妹做开发任务，所以我团队合作这方便还算熟悉；

我的自我介绍就差不多就这些

然后当然秋招在即，加上自己缺少企业实战经历，所以我目前是在寻找Java开发岗位的实习，所以投递并参加了贵公司针对Java实习岗位的面试。

需要我简单介绍一下简历中的项目吗？

简历中写的待见项目，是我在大三下也就是现在还在参与开发的一个项目，目前大体功能已经开发完毕；这是一个简单的电商项目，主要用途是进行学校的比赛，项目分成三个主要模块：社交、商城和支付系统；主要技术栈SpringBoot+MySQL+Redis，简单使用了RabbitMQ；

我本人负责的主要是商城系统的开发：主要完成的是订单、购物车、商品类目等业务的逻辑实现；

我的大致介绍就是这些。

## Spring中Bean生命周期

**Bean作用域**

- **单例对象：**singleton

  生命周期与容器相同

- **多例对象：**prototype

  出生：使用对象时创建

  活着：对象只要使用就一直或者

  死亡：当对象长时间不用且没有其他对象引用时，由Java垃圾回收机制回收

- **session：**生命周期和会话相同

- **request:** 生命周期和请求相同

****

**Bean生命周期：**

- **Bean实例化**

  通过反射方式进行对象的创建，此时创建只是在堆中开辟内存空间，属性都是默认值

- **注入对象属性**

  给对象中的属性进行值的设置

- **执行Aware**

- **BeanPostProcessor的前置处理**
- **InitalizingBean、init-method的检查执行**
- **BeanPostProcessor的后置处理**
- **注册回调方法**
- **Bean使用**
- **执行销毁方法**

​	![image-20230423144715834](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230423144715834.png)

## 创建线程的三种方式

- 继承Thread类，重写run()方法
- 实现Runnable接口，重写run()方法，传参给Thread
- 实现Callable接口，重写call()方法，call()方法作为线程执行体，具有返回值；传参给FutureTask，交给Thread执行

Thread.start()执行线程任务

## Spring有哪些模块

- Spring Core 框架最基础部分，提供IOC容器，对bean进行管理
- Spring Context，基于bean，提供上下文信息，扩展出国际化等功能
- Spring DAO JDBC抽象层，提供声明式事务处理方法
- Spring ORM，提供了对象/关系映射 API
- Spring AOP 面向切面编程的实现
- Spring Web 提供了基础的Web开发功能
- Spring Web MVC 提供了web应用的Model-vier-controller全功能实现

## AOP实现原理

- 实现接口的类采用JDK自带的动态代理：基于反射机制
- 未实现接口的类采用CGLIB：代理对象类的class文件加载进来，通过修改其字节码生成子类来处理

## Spring中的Bean是否线程安全

Spring容器本身没有提供线程安全策略，应当说是不安全的

- 对于singleton，因为是采用单例多线程的方法，默认线程不安全，但是开发中的大部分bean都是无状态的，不需要保证线程安全

  > 无状态：表示这个实例没有属性对象，不能保存实数据，是不变的类。比如：controller、service、dao。
  >
  > 有状态：表示实例是有属性的对象，可以保存数据，是线程不安全的，比如：pojo。

- 对于prototype：每次都生成一个新的对象，不存在线程安全问题



但是如果要保证线程安全，可以将bean的作用域改为prototype，比如像Model View。

另外还可以采用**ThreadLocal**来解决线程安全问题。ThreadLocal为每个线程保存一个副本变量，每个线程只操作自己的副本变量。

## Mybatis底层

mybatis底层是对jdbc的封装，也要经历jdbc获取连接、、编写sql、获取sql执行对象、封装参数、执行等步骤

## #{}和${}的区别是什么？

1. `#{}` 是预编译处理，`${}`是字符串替换。
2. Mybatis在处理`#{}`时，会将sql中的`#{}`替换为?号，调用PreparedStatement的set方法来赋值；
3. Mybatis在处理`${}`时，就是把`${}`替换成变量的值。
4. 使用`#{}`可以有效的防止SQL注入，提高系统安全性。

## Mybatis如何防止sql注入

- parameterType和ResultType校验参数类型

- mybatis采用了预编译功能，对于`#{}`会编译成sql的`?`占位符，并使用`PreparedStatement`的set方法赋值，并且赋值会加上`""`

  ```java
  select id, username, password from user where username=? and password=?
  ```

  

## Mybatis工作流程

关于MyBatis的工作原理，网上的文章是汗牛充栋，但是站长觉得，要结合JDBC来理解MyBatis的工作原理往往才能更透彻。我们知道，JDBC有四个核心对象：
（1）**DriverManager**，用于注册数据库连接
（2）**Connection**，与数据库连接对象
（3）**Statement/PrepareStatement**，操作数据库SQL语句的对象
（4）**ResultSet**，结果集一张虚拟表

而MyBatis也有四大核心对象：
（1）**SqlSession对象**，该对象中包含了执行SQL语句的所有方法。类似于JDBC里面的Connection 。
（2）**Executor接口**，它将根据SqlSession传递的参数动态地生成需要执行的SQL语句，同时负责查询缓存的维护。类似于JDBC里面的Statement/PrepareStatement。
（3）**MappedStatement**对象，该对象是对映射SQL的封装，用于存储要映射的SQL语句的id、参数等信息。
（4）**ResultHandler对象**，用于对返回的结果进行处理，最终得到自己想要的数据格式或类型。可以自定义返回类型。

![img](http://www.mybatis.cn/usr/uploads/2019/10/326517643.png)

## String类可以被继承吗

String类不可以被继承，String类被final关键字修饰；

并且底层char[]数组也用了private final修饰，引用不可修改，不可被外界访问，不提供公开的set方法

```java
public final class String
    implements java.io.Serializable, Comparable<String>, CharSequence{
    // 存储字符，实际使用字符数组存储的，final体现了不可变性
    // 私有避免了外界直接访问来对String进行修改
     private final char value[];
     
     //缓存字符串的hashcode，比如在hashmap中，不必每次比较就计算一次hash值
     private int hash; 
    ...
}
```

## String、builder、buffer

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterjava-string-20201208.png)

- **String：**不可变字符串，实现`Charsequence`接口，底层是final类，持有private final修饰的char[]数组

`StringBuilder`和`StringBuffer`继承抽象类`AbstractStringBuilder`；后者实现了`Charsequenced`和`Appendable`接口，也就说Builder和Buffer支持对字符串的修改

- **StringBuilder：**线程不安全
- **StringBuffer：**线程安全，对方法施加了synchronized锁

## 项目中线程池的使用

- 创建ThreadPoolConfig配置类，添加@Configuration、@EnableAsync注解

- 在配置类中编写一个创建Bean的方法（@Bean）

  return 一个 new ThreadPoolTaskExecutor()（线程）

- 然后在ThreadService里编写需要线程池执行的任务方法，用@Async注解

- 在service里调用方法，spring会自动交给线程池去处理

## TODO-Java中的锁

- **Sychronized：**Java语言关键字，JVM层面的锁

  Synchronized也是可重入锁

- **ReentrantLock：**Java提供的API层面的锁

  - ReentrantLock是一个可重入的互斥锁，又被称为“独占锁”。

  - ReentrantLock锁在**同一个时间点只能被一个线程锁持有**；

    可重入表示，ReentrantLock锁可以被**同一个线程**多次获取。

  - ReentrantLock是通过一个FIFO的等待队列来管理获取该锁所有线程的。

    在“公平锁”的机制下，线程依次排队获取锁；而“非公平锁”在锁是可获取状态时，不管自己是不是在队列的开头都会获取锁。（默认非公平锁）

  - 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待（一定程度上可以避免死锁）

## 红黑树和平衡二叉树区别

1、红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树]的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。

2、平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。

## MySQL

## 行锁和表锁的区别

## 如何解决依赖冲突

## servlet是否线程安全



## TODO-Linux常用命令

```shell
ls 显示文件目录
	-l 列出文件详细信息
	-a 列出当前目录下所有文件及目录
mkdir 创建目录
	-p 创建父目录
cd	切换目录
touch 创建空文件
echo 创建带有内容的文件
cat 查看文件内容
cp 拷贝
mv 移动或重命名
rm 递归删除
find 搜索文件
```



## TODO-Git切换分支合并分支

## TODO-Maven常用命令

